\chapter{Klassische Verfahren zur optimalen Steuerung}
\section{Grundproblem der Variationsrechnung}
\label{sec:kap_2_grundproblem}
Die Aufgabe besteht im Auffinden einer stetig differenzierbaren Funktion $x:[t_0,t_e]\rightarrow\mathbb{R}$ mit den Randbedingungen $x(t_0)=x_0$, $x(t_e)=x_e$, so dass ein
Gütefunktional $J=\int\limits_{t_0}^{t_e}f(t,x,\dot{x}) dt$ minimal wird.

Mit der Vorgehensweise von Euler wird angenommen, man hätte eine optimale Lösung $x^{\ast}$ gefunden. Konstruiere eine einparametrige Schar von Vergleichskurven
$x(t)=x^{\ast}+\epsilon\tilde{x}(t)$, wobei $\epsilon\in(-\epsilon_0,+\epsilon_0)$ ein Parameter ($\epsilon>0$ gegeben) und $\tilde{x}$ eine gegebene, stetig differenzierbare Funktion
mit $\tilde{x}(t_0)=0$, $\tilde{x}(t_e)=0$ ist.
\begin{figure}[htb]
	\centering
	\input{tikz/dummy}
	\caption{Vorgehensweise von Euler}
	\label{fig:kap_2_vorg_euler}
\end{figure}
Die Funktion $\delta x^{\ast}:= \epsilon\tilde{x}$ heisst Variation von $x^{\ast}$ und das einsetzen in $J$ liefert 
\begin{align*}
	F(\epsilon) & := \int\limits_{t_0}^{t_e}f(t,x^{\ast}(t)+\epsilon\tilde{x}(t),\dot{x}^{\ast}(t)+\epsilon\dot{\tilde{x}}(t))dt.
\end{align*}
Sei $f$ zweifach stetig differenzierbar. Die Funktion $F:(-\epsilon_0,+\epsilon_0)\rightarrow\mathbb{R}$ hat für $\epsilon=0$ ein Minimum, also muss gelten
\begin{align*}
	\left.\frac{\td F}{\td \epsilon}\right|_{\epsilon_0} & = \int\limits_{t_0}^{t_e}\left[\frac{\td f}{\td x}\tilde{x}(t)+\frac{\d
	f}{\td\dot{x}}\dot{\tilde{x}}(t) \right]dt = 0.
\end{align*}
Mit partieller Integration 
\begin{align*}
	\int\limits_{t_0}^{t_e}\underbrace{\frac{\td F}{\td \dot{x}}\dot{\tilde{x}}(t)}_{u\cdot v'}dt & = \bigg[\underbrace{\frac{\d
	F}{\td\dot{x}}\tilde{x}}_{u\cdot v}\bigg]_{t=t_0}^{t=t_e}-\int\limits_{t_0}^{t_e} \underbrace{\frac{\td}{\td t}\frac{\td
	F}{\partial\dot{x}}\tilde{x}(t)}_{u'\cdot v}dt
\end{align*}
ergibt sich
\begin{align*}
	\int\limits_{t_0}^{t_e}\left[\frac{\td F}{\td x}-\frac{\td}{\td t}\frac{\td F}{\td\dot{x}} \right]\tilde{x}(t)dt & = 0
\end{align*}
und da $\tilde{x}$ (bis auf die Randwerte) beliebig ist, muss 
\begin{align}
	\frac{\td F}{\td x}-\frac{\td}{\td t}\frac{\td F}{\td\dot{x}} & = 0 \label{eqn:kap_2_euler_lag_dgl}
\end{align}
gelten.
\begin{remark}{Fundamentallemma der Variationsrechnung}
Sei $G:\left[a,b \right]\rightarrow\mathbb{R}^1$ stetig und gelte $\int\limits_a^b G(t)v(t)dt=0$ für alle stetig differenzierbaren Funktionen $v$ mit
$v(a)=v(b)=0$. Dann gilt $G(t)=0\forall t\in\left[a,b \right]$.
\begin{figure}[htb]
	\centering
	\input{tikz/dummy}
	\caption{Darstellung Fundamentallemma der Variationsrechnung}
	\label{fig:kap_2_fundlemma_var}
\end{figure}
\end{remark}
Dies ist eine gewöhnliche Differentialgleichung 2. Ordnung mit der Lösung $x=x(t,c_1,c_2)$. Eine Anappsung an die Randbedingungen $x(t_0,c_1,c_2)=x_0$
und $x(t_e,c_1,c_2)=x_e$ liefert $c_1$, $c_2$.
\begin{exmp}
Gegeben sind $P_0=(t_0,x_0)$ und $P_e=(t_e,x_e)$ in der Ebene. Gesucht ist die kürzeste Verbindung zwischen $P_0$ und $P_e$. Ein Bogenelement ist
beschrieben durch 
\begin{align*}
	ds^2 & = dt^2 + dx^2 = \left(1+\dot{x}^2 \right)dt^2
\end{align*}
und zu minimierende Bogenlänge, der durch $s:t\in\left[t_0,t_e \right]\mapsto \begin{bmatrix}
t\\ x(t)
\end{bmatrix}$ parametrisieirte Kurve liefert
\begin{align*}
	J  & = \int\limits_{P_0}^{P_e}ds=\int\limits_{t_0}^{t_e}\underbrace{\sqrt{1+\dot{x}^2}}_{f(t,x,\dot{x})}dt.
\end{align*}
Wegen $f_x=0$, $f_{\dot{x}}=\frac{\dot{x}}{\sqrt{1+\dot{x}^2}}$ wird aus \eqnref{eqn:kap_2_euler_lag_dgl} 
\begin{align*}
	\frac{\td}{\td t}\frac{\dot{x}}{\sqrt{1+\dot{x}^2}} & = 0,
\end{align*}
also $\frac{\dot{x}}{\sqrt{q+\dot{x}^2}}=C$ mit der Integrationskonstante $C$. Wegen $\dot{x}=c\sqrt{\frac{1}{1-c^2}}$ gibt es $c_1$ und $c_2$, so
dass $x(t)=c_1 t+c_2$. Anpassung an die \ac{RB} liefert Geradengleichung durch $P_0$ und $P_e$.
\end{exmp}
\section{Formulierung des Optimierungsproblems und Lösung}
Ausgehend vom Kostenfunktional
\begin{align*}
	J & = h\left(x(t_b),t_b \right) + \int\limits_{t_a}^{t_b}f_0\left(x(t),u(t),t \right)dt\rightarrow \min!
\end{align*}
kann der Prozess, die \ac{AB} und die \ac{EB} definiert werden\\
\begin{tabular}{ll}
Prozess: & $\dot{x}(t)=f\left(x(t),u(t),t \right)$\\
\ac{AB}: & $x(t_a)=x_a$ mit gegebenen $t_a$ und $x_a\in\mathbb{R}^n$\\
\ac{EB}: & mit $t_b$ frei und/oder $t_b$ gegeben:\\
		 & Fall A: $z\left(x(t_b) \right)=0$ mit gegebenen $z:\mathbb{R}^n\rightarrow\mathbb{R}^m$\\
		 & Fall B: $x(t_b)=x_b$ mit geg. $x_b\Leftrightarrow z(x(t_b)):=x(t_b)-x_b=0$\\
		 & Fall C: $x(t_b)$ frei, d.h. $z\equiv 0$ 
\end{tabular}
$h$, $f_0$, $f$, $z$ sind stetig differenzierbar bezüglich aller Argumente. Es gibt keine Beschränkung von $u(t)$ und $x(t)$ für $t\in\left(t_a, t_b
\right)$.\\
Falls $t_b$ gegeben ist und Fall B besteht, so ist $h(x(t_b),t_b)$ fest und kann aus Kostenfunktional gestrichen werden.

\subsection{Prinzip der Herleitung notwendiger Bedingungen}
\label{sec:kap_2_pr_herl_not_bed}
Die Einführung der Lagrange-Multiplikatoren liefert
\begin{align*}
	\bar{J} & = h\left(x(t_b),t_b \right)+\int\limits_{t_a}^{t_b}\left[f_0\left(x(t),u(t),t \right)+\psi(t)^T\left(f(x(t),u(t),t)-\dot{x}(t) \right)
	\right]dt\\
	& \quad + \lambda_a^T\left\{x_a - x(t_a) \right\} + \lambda_b^T z\left(x(t_b) \right)
\end{align*}
mit $\lambda_b\in\mathbb{R}^m$, $\lambda_a\in\mathbb{R}^n$.

Die Motivation ist, dass 
\begin{align*}
	J & = \int F_0(x(t))dt \rightarrow \min
\end{align*}
bei $\underbrace{f\left(x(t), u(t) \right)-\dot{x}(t)=0 }_{h\left(x(t),u(t) \right)\in\mathbb{R}^n }$ dargestellt werden kann in diskreter Form als
\begin{align*}
	J_{diskret} & = \sum\limits_j f_0(x(t_j))\rightarrow \min 
\end{align*}
bei $\left. h\left(x(t_j),u(t_j) \right)\right|_{\forall j}=0$ bzw.
\begin{align*}
	L_{diskret} & = \sum\limits_j f_0(x(t_j)) + \sum\limits_j \underbrace{\psi_j^T}_{=:\psi(t_j)} h\left(x(t_j),u(t_j) \right).
\end{align*}
Dies kann wiederrum dargestellt werden in der Form
\begin{align*}
	\bar{J} & = \int\left(f_0(x(t)) \right) + \psi(t)^T\left(f(x(t),u(t))-\dot{x}(t) \right).
\end{align*}
Es wird die Hamilton-Funktion definiert mit
\begin{align*}
	\Ham\left(x(t),u(t),\psi(t),t \right) & = f_0\left(x(t),u(t),t \right) + \psi(t)^T f\left(x(t),u(t),t \right)
\end{align*}
und erhalten 
\begin{align}
	\begin{split}\label{eqn:kap_2_lagrange_fun}
		\bar{J} & = h\left(x(t_b),t_b \right) + \int\limits_{t_a}^{t_b}\left[H\left(x(t),u(t),\psi(t),t \right)-\psi(t)^T\dot{x}(t) \right]dt\\
				& \quad +\lambda_a^T\left\{x_a-x(t_a) \right\} + \lambda_b^T z\left(x(t_b\right).
	\end{split}
\end{align}
Angenommen wir hätten die optimale Lösung gefunden und wir betrachten die Variationen der Funktionen $u$, $x$, $\psi$ und damit auch $\dot{x}$ auf dem
Intervall $\left(t_a, t_b \right)$, den Vektoren $x(t_a)$, $\lambda_a$, $x(t_b)$, $\lambda_b$ und der Zahl $t_b$, d.h.
$\xi(t)=\xi^{\ast}(t)+\epsilon\tilde{\xi}(t)$ mit $\xi\in\left\{x(t_a),\lambda_a, x(t_b), \lambda_b, t_b\right\}$. Einsetzen in
\eqnref{eqn:kap_2_lagrange_fun} liefert die Lagrange-Funktion
\begin{align*}
	\begin{split}
		\bar{J} & = h\left(x^{\ast}\left(t_b^{\ast}+\epsilon\tilde{t}_b \right) +\epsilon\tilde{x}\left(t_b^{\ast}+\epsilon\tilde{t}_b \right),
		t_b^{\ast}+\epsilon\tilde{t}_b \right)\\
		& \quad + \int\limits_{t_a}^{t_b^{\ast}+\epsilon\tilde{t}_b}\left[\Ham\left(x^{\ast}(t)+\epsilon\tilde{x}(t), u^{\ast}(t)+\epsilon\tilde{u}(t),
		\psi^{\ast}(t)+\epsilon\tilde{\psi}(t),t \right) \right.\\
		& \left. \quad - \left(\psi^{\ast}(t)+\epsilon\tilde{\psi}(t) \right)^T\left(\dot{x}^{\ast}(t)+\epsilon\tilde{\dot{x}}(t) \right)\right]dt\\
		& \quad + \left(\lambda_a^{\ast T}+\epsilon\tilde{\lambda}_a^T \right)\left\{x_a - \left(x^{\ast}(t_a)+\epsilon\tilde{x}(t_a)\right) \right\}\\
		& \quad + \left(\lambda_b^{\ast T}+\epsilon\tilde{\lambda}_b^T \right)z\left(x^{\ast}\left(t_b^{\ast}+\epsilon\tilde{t}_b \right) +
		\epsilon\tilde{x}\left(t_b^{\ast} + \epsilon\tilde{t}_b \right) \right).
	\end{split}
\end{align*}
Man hat
\begin{align*}
	& \frac{\td h}{\td\epsilon}\left(x^{\ast}\left(t_b^{\ast}+\epsilon\tilde{t}_b^{\ast} \right) + \epsilon\tilde{x}\left(t_b^{\ast}+ \epsilon\tilde{t}_b
	\right),t_b^{\ast} + \epsilon\tilde{t}_b \right)\\
	=  & \frac{\d h}{\d x}(\ldots)\left(\dot{x}^{\ast}\left(t_b^{\ast}+\epsilon\tilde{t}_b \right)+\tilde{x}\left(t_b^{\ast}\right)+\epsilon\tilde{t}_b +
	\epsilon\tilde{\dot{x}} \left(t_b^{\ast}+\epsilon\tilde{t}_b \right)\tilde{t}_b \right) + \frac{\d h}{\d t}(\ldots)\tilde{t}_b
\end{align*}
und damit
\begin{align*}
	& \left.\frac{\td h}{\td\epsilon}\left(x^{\ast}\left(t_b^{\ast}+\epsilon\tilde{t}_b \right) + \epsilon\tilde{x}\left(t_b^{\ast}+\epsilon\tilde{t}_b 
	\right),t_b^{\ast}+\epsilon\tilde{t}_b \right)\right|_{\epsilon = 0}\\
	= & \frac{\d h}{\d x}\left(x^{\ast}(t_b^{\ast}),t_b^{\ast} \right)\left(\dot{x}^{\ast}(t_b^{\ast})\tilde{t}_b + \tilde{x}(t_b^{\ast}) \right) +
	\frac{\d h}{\d t}(\ldots)\tilde{t}_b\\
	= & \frac{\d h}{\d x}\left(x^{\ast}(t_b^{\ast}),t_b^{\ast} \right)\dot{x}^{\ast}(t_b^{\ast})\tilde{t}_b + \underbrace{\frac{\d h}{\d
	x}\left(x^{\ast}(t_b^{\ast}),t_b^{\ast} \right)\tilde{x}(t_b^{\ast}) }_{=:\left.\frac{\d h}{\d x}\right|_{t_b} \tilde{x}(t_b)}.
\end{align*}
Einsetzen in \eqnref{eqn:kap_2_lagrange_fun} liefert analog zu Abschnitt \secref{sec:kap_2_grundproblem} die Funktionen $F(\epsilon)$ und
\begin{align*}
	\left.\frac{\td F}{\td \epsilon}\right|_{\epsilon=0} & = \left.\frac{\d h}{\d x}\right|_{t_b}\tilde{x}(t_b) + \left[\frac{\d h}{\d x}\dot{x} +
	\frac{\d h}{\d t}+\Ham - \psi^T\dot{x} \right]_{t_b}\tilde{t}_b\\ 
	& \quad + \int\limits_{t_a}^{t_b}\left[\frac{\d\Ham}{\d
	x}\tilde{x}+\frac{\d\Ham}{\d u}\tilde{u}+\frac{\d\Ham}{\d\psi}\tilde{\psi} - \tilde{\psi}^T\dot{x} - \psi^T\tilde{\dot{x}}\right]dt \\
	& \quad + \tilde{\lambda}_a^T\left\{x_a-x(t_b) \right\} - \lambda_a^T\tilde{x}(t_a)+\tilde{\lambda}_b^T z(x(t_b)) \\
	& \quad + \left.\lambda_b^T\frac{\d z}{\d x}\right|_{t_b}\tilde{x}(t_b)+\lambda_b^T\frac{\d z}{\d x}\dot{x}(t_b)\tilde{t}_b
\end{align*}
mit 
\begin{align*}
	\int\limits_{t_a}^{t_b}\psi^T\tilde{\dot{x}}dt & = \psi^T(t_b)\tilde{x}(t_b)-\psi^T(t_a)\tilde{x}(t_a)-\int\limits_{t_a}^{t_b}\dot{\psi}^T\tilde{x}dt
\end{align*} 
durch partielle Integration ergibt sich
\begin{align*}
\left.\frac{\td F}{\td \epsilon}\right|_{\epsilon=0} & = \textcolor{magenta}{\left[\frac{\d h}{\d t}+\Ham \right]_{t_b}\tilde{t}_b} + \int\limits_{t_a}^{t_b}\left[
\textcolor{teal}{\left(\frac{\d\Ham}{\d x}+\dot{\psi}^T \right)\tilde{x}} + \textcolor{olive}{\frac{\d\Ham}{\d u}\tilde{u}} +
\textcolor{lime}{\left(\frac{\d\Ham}{\d\psi}-\dot{x}^T \right)\tilde{\psi}} \right]dt\\
& \quad + \textcolor{green}{\tilde{\lambda}_a^T\left\{x_a - x(t_a) \right\}} + \left(\psi^T(t_a) - \lambda_a^T \right)\tilde{x}(t_a) +
\textcolor{darkgray}{\tilde{\lambda}_b^Tz(x(t_a))} \\
& \quad + \textcolor{cyan}{ \left[\lambda_b^T\frac{\d z}{\d x}+\frac{\d h}{\d x}-\psi^T \right]_{t_b}\left(\tilde{x}(t_b)+\dot{x}(t_b)\tilde{t}_b \right)}\\
& = 0
\end{align*}

\subsection{Notwendige Bedingungen für Optimallösung}
Die Prozessgleichung wird definiert als
\begin{align}
	\textcolor{lime}{\dot{x}(t) = \nabla_{\psi}\Ham} & = f\left(x(t),u(t),t \right). \label{eqn:kap_2_prozessgleichung}
\end{align}
Die dazugehörige adjungierte Prozessgleichung\footnote{Es kann geschrieben werden \begin{align*}
\frac{\d\Ham}{\d x} & = \frac{\d f_0}{\d x}+\psi^T\underbrace{\frac{\d f}{\d x}}_{\in\mathbb{R}^{n\times n}}\\
\nabla_x\Ham & = \nabla_x f_0+\left[\frac{\d f}{\d x} \right]^T\psi
\end{align*}} ist beschrieben durch
\begin{align}
	\textcolor{teal}{\dot{\psi}(t) = -\nabla_x\Ham } & = -\nabla_x f_0\left(x(t),u(t),t \right)-\left[\frac{\d f}{\d x}(x(t),u(t),t) \right]^T\psi(t) \label{eqn:kap_2_adj_prozessglg}
\end{align}
und die Steuerungsgleichung durch
\begin{align}
	\textcolor{olive}{\nabla_u\Ham\left(x(t),u(t),\psi{t},t \right)} & = 0. \label{eqn:kap_2_steuergleichung}
\end{align}
Dabei bilden Gleichung \eqnref{eqn:kap_2_prozessgleichung} und \eqnref{eqn:kap_2_adj_prozessglg} die kanonischen Differentialgleichungen und \eqnref{eqn:kap_2_prozessgleichung},
\eqnref{eqn:kap_2_adj_prozessglg} und \eqnref{eqn:kap_2_steuergleichung} die sogenannten Hamilton-Gleichungen.\\
\begin{tabular}{lll}
\ac{AB} & \textcolor{green}{$x(t_a)=x_a$}\\
\ac{EB} & Fall A: 	& \textcolor{darkgray}{$z(x(t_b))=0$} und die Transversalitätsbedingung\\
		&			& \textcolor{cyan}{$\left[\frac{\d z}{\d x}(x(t_b)) \right]^T\lambda_b +\nabla_x
h(x(t_b),t_b)-\psi(t_b)=0$} \\
		& Fall B: 	& $x(t_b)=t_b$ mit bekannten $x_a$ und $x_b$\\
		& Fall C: 	& $\nabla_x h(x(t_b),t_b)=\psi(t_b)$\\
		&			& Fall $t_b$ frei ist, so muss zusätzlich $\Ham(x(t_b),u(t_b),\psi(t_b),t_b)=\textcolor{magenta}{-\frac{\d h}{\d t}(x(t_b),t_b)}$\\
		&			& erfüllt sein.
\end{tabular}

\subsection{Grundsätzliche Vorgehensweise zur analytischen Bestimmung der Optimallösung}
\begin{enumerate}[label=(S\arabic*)]
  \item Umstellen der Steuerungsgleichung nach $u$ liefert 
  \begin{align}
  	u(t) & = \mathcal{U}\left(x(t),\psi(t),t \right). \label{eqn:kap_2_vor_optlsg_s1_u}
  \end{align}
  Einsetzen in kanonsiche Differentialgleichung (Elimination von $u$ ergibt)
  \begin{align}
  	\dot{x} & = w(x,\psi,t). \label{eqn:kap_2_vor_optlsg_s1_x}
  \end{align}
  \item Bestimmen der allgemienen Lösung von \eqnref{eqn:kap_2_vor_optlsg_s1_x} mit dem Integrationsparameter $c\in\mathbb{R}^{2n}$
  \begin{align}
  	x & = x(t,c), & \psi=\psi(t,c)	\label{eqn:kap_2_vor_optlsg_s2}
  \end{align}
  \item Anpassung der Lösung an die Randbedingungen\\
  \begin{tabular}{ll}
  Fall A	& $x(t_a,c)=x_a$, $z\left(x(t_b,c) \right)=0$,\\ 
  			& $\left[\frac{\d z}{\d x}\left(x(t_b,c) \right) \right]^T\underbrace{\lambda_b}_{\in\mathbb{R}^m}+\nabla_x h\left(x(t_b,c),t_b
  			\right)-\psi(t_b,c)=0$\\
  Fall B	& $x(t_a,c)=x_a$, $x(t_b,c)=x_b$\\
  Fall C	& $x(t_a,c)=x_a$, $\nabla_x h\left(x(t_b,c),t_b \right) = \psi(t_b,c)$\\
  			& Falls $t_b$ frei ist: $\Ham\left(x(t_b,c),\mathcal{U}(x(t_b,c)),\psi(t_b,c),t_b \right)=\frac{\d h}{\d t}\left(x(t_b,c),t_b \right)$
  \end{tabular}\\
  Dabei $x_a$ als Variable mitführen, also ist $c=c(x_a)$. Falls $t_b$ frei ist, so gilt $t_b=t_b(x_a)$.
  \item Einsetzen von $c(x_a)$ in \eqnref{eqn:kap_2_vor_optlsg_s2} ergibt die optimale (Zustands- und Kozustands-)Trajektorie 
  \begin{align}
  	x\left(t,c(x_a) \right) & =: x^{\ast}(t,x_a)	\label{eqn:kap_2_vor_optlsg_s4}
  \end{align}
  und 
  \begin{align*}
  	\psi\left(t,c(x_a) \right) & =: \psi^{\ast}(t,x_a).
  \end{align*}
  Eingesetzt in \eqnref{eqn:kap_2_vor_optlsg_s1_u} erhält man die optimale Steuertrajektorie
  \begin{align}
  	\mathcal{U}\left(x^{\ast}(t,x_a), \psi^{\ast}(t,x_a),t \right) & =: u^{\ast}(t,x_a).	\label{eqn:kap_2_vor_optlsg_s5}
  \end{align}
  \item Umstellen von \eqnref{eqn:kap_2_vor_optlsg_s4} nach $x_a$ und einsetzen in \eqnref{eqn:kap_2_vor_optlsg_s5} liefert das Regelgesetz
  \begin{align*}
  	u^{\ast}(t) & = K\left(x(t),t \right).
  \end{align*}
\end{enumerate}
Die Schritte (S1) bis (S4) liefern die in \figref{fig:kap_2_vor_optlsg_s1s4} dargestellten Trajektrtorien und Schritt (S5) die in
\figref{fig:kap_2_vor_optlsg_s5} dargestellte Trajektorie.
\begin{figure}[htb]
	\centering
	\input{tikz/dummy}
	\caption{Trajektorien der Schritte (S1) bis (S4)}
	\label{fig:kap_2_vor_optlsg_s1s4}
\end{figure}
\begin{figure}[htb]
	\centering
	\input{tikz/dummy}
	\caption{Trajektorie des Schrittes (S5)}
	\label{fig:kap_2_vor_optlsg_s5}
\end{figure}
\begin{exmp}\label{exmp:kap_2_vor_optlsg_1}
Sei $\dot{x}=ax+bu$ mit $a,b\in\mathbb{R}^1$, $t_a=0$, $x(0)=x_a$ gegeben. Weiterhin ist $t_b$ gegeben und damit nicht frei. $x(t_b)=0$, d.h. es
wird Fall B betrachtet mit dem "`energieoptimalen"' Kostenfunktional 
\begin{align*}
	J & = \frac12\int\limits_0^{t_b}u(t)^2dt.
\end{align*}
Wir haben
\begin{align*}
	\Ham & = \frac12 u^2 + \psi(ax+bu),\\
	\dot{x} & = \nabla_{\psi}\Ham = ax+bu,\\
	\dot{\psi} & = -\nabla_x\Ham = -a\dot \psi,\\
	\nabla_u\Ham & = u+b\psi = 0.
\end{align*}
Damit ist 
\begin{align}
	u & = -b\psi.	\label{eqn:kap_2_vor_optlsg_u}
\end{align}
Im nächsten Schritt werden die kanonischen Differentialgleichungen gelöst. Die Lösung von 
\begin{align*}
	\dot{x} & = ax - b^2\psi\\
	\dot{\psi} & = -a\cdot\psi
\end{align*}
liefert
\begin{align}
	x(t) & = x(0)e^{at}+\frac{b^2\psi(0)}{2a}\left(e^{-at}-e^{at} \right)	\label{eqn:kap_2_vor_optlsg_x}\\
	\psi(t) & = \psi(0)e^{-at}.		\label{eqn:kap_2_vor_optlsg_psi}
\end{align}
In \eqnref{eqn:kap_2_vor_optlsg_x} wird $t=t_b$ zur Betrachtung des Endzeitpunktes $t_b$ gesetzt und $x(t_b)= 0$. Umstellen nach $\psi(0)$ liefert
\begin{align}
	\psi(0) & = -\frac{2a}{b^2}\frac{e^{at_b}}{e^{-at_b}-e^{at_b}}x(0).	\label{eqn:kap_2_vor_optlsg_psi0}
\end{align}
Eingesetzt in \eqnref{eqn:kap_2_vor_optlsg_x} erhält man
\begin{align}
	x^{\ast}(t,x(0)) & = x(0)\frac{e^{-a(t_b-t)}-e^{a(t_b-t)}}{e^{-at_b}-e^{at_b}}	\label{eqn:kap_2_vor_optlsg_xast}
\end{align}
und \eqnref{eqn:kap_2_vor_optlsg_u} wird mit \eqnref{eqn:kap_2_vor_optlsg_psi} und \eqnref{eqn:kap_2_vor_optlsg_psi0} zu
\begin{align}
\begin{split}\label{eqn:kap_2_vor_optlsg_uast}
	u^{\ast}(t,x(0)) & = -b\psi(0)e^{at}\\
	& = \frac{2a}{b}\frac{e^{a(t_b-t)}}{e^{-at_b}-e^{at_b}} x(0).
\end{split}
\end{align}
\eqnref{eqn:kap_2_vor_optlsg_xast} umgestellt nach $x(0)$ und eingesetzt in \eqnref{eqn:kap_2_vor_optlsg_uast} liefert das Regelgesetz
\begin{align}
	u^{\ast}(t) & = k(t) x(t)
\end{align}
mit
\begin{align*}
	k(t) & = \frac{2a}{b}\frac{e^{a(t_b-t)}}{e^{-a(t_b-t)}-e^{a(t_b-t)}}.
\end{align*}
Der optimale Regler ist linear, zeitvariant und es gilt
\begin{align*}
	\lim\limits_{t\rightarrow t_b}\left|k(t)\right| & = \infty.
\end{align*}
Eine Verstäkrung gegen $\infty$ ist sinnig. Sie entsteht durch die harten Endbedingungen. Es wären weiche Endbedingungen sinnvoll, siehe
\exmpref{exmp:kap_2_vor_optlsg_2}. Die Trajektorien von $u$, $x$ und $\psi$ sind in \figref{fig:kap_2_vor_optlsg_exmp_1} dargestellt. Der Verlauf der
Reglerverstärkung ist in \figref{fig:kap_2_vor_optlsg_exmp_2_k} abgebildet. 
\end{exmp}
\begin{figure}[htb]
	\centering
	\input{tikz/dummy}
	\caption{Trajektories von \exmpref{exmp:kap_2_vor_optlsg_1} mit festem Endzustand}
	\label{fig:kap_2_vor_optlsg_exmp_1}
\end{figure}
\begin{exmp}\label{exmp:kap_2_vor_optlsg_2}
Sei $\dot{x}=ax+bu$ mit $a,b\in\mathbb{R}^1$, $t_a=0$, $x(0)=x_a$ gegeben. $t_b$ wird als frei angenommen und das Kostenfunktional als
\begin{align*}
	J & = \frac12 Sy(t_b)^2 + \frac12\int\limits_0^{t_b}u(t)^2dt.
\end{align*}
Das heisst, es wird Fall C betrachtet. So ist anstelle von $x(t_b)=0$ die Randbedinung $Sx(t_b)=\psi(t_b)$ zu erfüllen. Darin müssen Gleichung
\eqnref{eqn:kap_2_vor_optlsg_x} und \eqnref{eqn:kap_2_vor_optlsg_psi} an der Stelle $t=t_b$ eingesetzt und nach $\psi(0)$ umgestellt werden. Damit
erhält man $x^{\ast}\left(t,x(0) \right)$, $\psi^{\ast}\left(t,x(0) \right)$ und $u^{\ast}\left(t,x(0) \right)$, sowie das Regelgesetz
\begin{align*}
	u^{\ast}(t) & = k(t) x(t)
\end{align*}
mit
\begin{align*}
	k(t) & = \frac{-2a S}{b\left(S-\left(S-\frac{2a}{b^2} \right)e^{-2a(t_b-t)} \right)}
\end{align*}
für den gilt, dass $k(t_b)=-bS$ gilt.

Für $t_b\rightarrow\infty$ gilt für jedes $t$ in beiden Fällen
\begin{align*}
	k(t) & = \left\{\begin{array}{cl}
	0 & \text{für} a < 0\\
	unbestimmt & \text{für} a = 0\\
	-\frac{2a}{b} & \text{für} a > 0
	\end{array}\right. .
\end{align*}
Der Prozess ist bei $a<0$ stabil und damit ist kein Stellaufwand notwendig. Wenn der Prozess instabil ist, $a > 0$, konvergiert der Zustand gegen
$\infty$. Wenn der Prozess integrales Verhalten aufweist, $a=0$, ist kein Minimum vorhanden.
\end{exmp}
\begin{figure}[htb]
	\centering
	\input{tikz/dummy}
	\caption{Trajektories von \exmpref{exmp:kap_2_vor_optlsg_2} mit Gewichtung des Endzustandes}
	\label{fig:kap_2_vor_optlsg_exmp_2}
\end{figure}
\begin{figure}[htb]
	\centering
	\input{tikz/dummy}
	\caption{Reglerverstärkungen von \exmpref{exmp:kap_2_vor_optlsg_1} und \exmpref{exmp:kap_2_vor_optlsg_2}}
	\label{fig:kap_2_vor_optlsg_exmp_2_k}
\end{figure}
Es sind zwei Übungen unter \picref{sec:uebung_anal_best_opt_lsg}{Vorgehensweise zur analytischen Bestimmung der Optimallösung} im Anhang zu finden.

\subsection{Numerische Lösung am Beispiel "`Fall C und fester Endzeit $t_b$"'}
Zur Lösung der "`Endwertaufgabe"' $\dot{\psi}=\nabla_x \Ham$ mit gegeben Endwert $\psi(t_b)$ und unter der Annahme, dass $x(t)$ und $u(t)$ gegeben
sind. Wir setzen $t=t(\tau)=t_b+t_a-\tau$, vgl. \figref{fig:kap_2_fallc_tbfest_ttau} und mit 
\begin{align*}
	\Psi(\tau) & := \psi(t(\tau)) = \psi(t_b+t_a-\tau)
\end{align*}
erhält man 
\begin{align*}
	\dot{\Psi}(\tau) & = \frac{d\psi(t(\tau))}{d\tau} = \left.\frac{d\psi(t)}{dt}\right|_{t=t(\tau)}\frac{dt}{d\tau}\\
	& = \left.-\frac{d\psi(t)}{dt}\right|_{t=t(\tau)}=\left.-\dot{\psi}(t)\right|_{t=t(\tau)}\\
	& = \left.\nabla_x \Ham(x(t),u(t),\psi(t),t)\right|_{t=\tau}
\end{align*}
\begin{figure}[htb]
	\centering
	\input{tikz/dummy}
	\caption{Darstellung der linearen Funktion $t=t(\tau)$}
	\label{fig:kap_2_fallc_tbfest_ttau}
\end{figure}
\begin{figure}[htb]
	\centering
	\input{tikz/dummy}
	\caption{Entwicklung von $\psi$ in Abhängigkeit von $t$ und $\tau$}
	\label{fig:kap_2_fallc_tbfest_psi}
\end{figure}
Damit ist die Anfangswertaufgabe 
\begin{align*}
	\dot{\Psi}(\tau) & = \nabla_x \Ham(x(t_b+t_a-\tau),u(t_b+t_a-\tau),\psi(\tau),t_b+t_a-\tau)
\end{align*}
mit dem \ac{AW} $\Psi(t_a)=\psi(t_b)$ zu lösen für $\tau\in[t_a,t_b]$ und es gilt
\begin{align*}
	\psi(t) & = \psi(t_b+t_a-\tau).
\end{align*}

Zur Lösung des nichtlinearen Gleichungssystems $\nabla_u \Ham =0$ kann das \textsc{Newton}-Verfahren verwendet werden. Bekannt ist, dass für eine
differenzierbare Funktion $f:\mathbb{R}^1\rightarrow\mathbb{R}^1$ gilt
\begin{align*}
	f(x) & = f(\bar{x})+f'(\bar{x})(x-\bar{x})+\mathcal{O}(x-\bar{x}),
\end{align*}
wobei $\mathcal{O}(h)$ für eine beliebeige Funktion $g:\mathbb{R}^1\rightarrow\mathbb{R}^1$ mit $\lim\limits_{h\rightarrow 0}\frac{g(h)}{h}=0$
steht.\\
\begin{figure}[htb]
	\centering
	\input{tikz/dummy}
	\caption{Darstellung \textsc{Newton}-Verfahren}
	\label{fig:kap_2_fallc_newton}
\end{figure}
$x=\bar{x}-\frac{f(x)}{f'(x)}$ liefert die iterative Vorschrift
\begin{align*}
	x^{k+1} & = x^k - \alpha\frac{f\left(x^k\right)}{f'\left(x^k \right)}
\end{align*}
mit $\alpha\in(0,1]$. Falls $\alpha\in(0,1)$ gilt, spricht man von einem gedämpften \textsc{Newton}-Verfahren. Allgemein für differenzierbare
Funktionen $F:\mathbb{R}^n\rightarrow\mathbb{R}^n$ kann geschrieben werden:\\
Löse $F(x)=0$ mittels
\begin{align*}
	x^{k+1} & = x^k - \alpha F'\left(x^k\right)^{-1}F(k)
\end{align*}
mit der Jacobimatrix $F'\left(x^k\right)$ an der Stelle $x^k$.

Bei der Anwendung des Verfahrens auf 
\begin{align*}
 \nabla_x\Ham\left(x(t),u(t),\psi(t),t \right) & = 0
\end{align*}
ergibt sich die Iterationsvorschrift zu
\begin{align*}
	u^{k+1}(t) & ) u^{k}(t) -\alpha\nabla_{uu}\Ham\left(x(t),u^k(t),\psi(t),t \right)^{-1}\nabla_u\Ham\left(x(t),u^k(t),\psi(t),t \right)
\end{align*}
Für ein gegebenes $x(t)$ und $\psi(t)$ ist die Vorschrift für alle $t$ abzuarbeiten.\\
Ein Algorithmus zur Bestimmung von $u$ kann wie folgt dargestellt werden.
\begin{enumerate}[label=(S\arabic*)]
  \item Setze einen Startwert $u(t)$, $t\in[t_a,t_b]$.
  \item Löse \ac{AWA} $\dot{x}=f\left(x(t),u(t),t \right)$ mit $x(t_a)=x_a$ und liefert $x(t)$, $t\in[t_a,t_b]$.
  \item Löse \ac{AWA}
  \begin{align*}
  	\dot{\Psi}(\tau) & = \nabla_x\Ham\left(x(t_b+t_a-\tau),u(t_b+t_a-\tau),\psi(\tau),t_b+t_a-\tau \right)\\
  	\Psi(t_a) & = \nabla_xh\left(x(t_b),t_b \right)
  \end{align*}
  mit $\tau\in[t_a,t_b]$ und liefert $\psi(t)=\Psi\left(t_b + t_a -\tau\right)$, $t\in[t_a,t_b]$.
  \item Aktualisiere 
  \begin{align*}
  	u(t) & \leftarrow u(t)-\underbrace{\alpha\nabla_{uu}\Ham\left(x(t),u(t),\psi(t),t \right)^{-1}\nabla_u\Ham\left(x(t),u(t),\psi(t),t \right)
  	}_{\Delta u}
  \end{align*} 
  mit $t\in[t_a,t_b]$.
  \item Falls Abbruchbedingung, bspw. $\|\Delta u\|$ klein oder $\|\Delta J\|$ klein, erfüllt ist, dann Stopp, andernfalls gehe zu (S2).
\end{enumerate}
\begin{exmp}
Es wird der vorgestellten Algorithmus in Form von Pseudocode auf das Beispiel \exmpref{exmp:kap_2_vor_optlsg_2} angewendet. Der Prozess ist
beschrieben durch
\begin{align*}
	\dot{x} & = ax + bu
\end{align*}
mit gegebenen $x(t_a)=x_a$ und $t_b$ und dem Kostenfunktional
\begin{align*}
	J & = \frac12 Sx(t_b)^2 + \frac12\int\limits_{t_a}^{t_b}u(t)^2dt. 
\end{align*}
\begin{enumerate}[label=(S\arabic*)]
  \item Setze Startwert für die zeitdiskretisierte Steuerfunktion $\begin{bmatrix}
  u(t_a)\\ \vdots\\ t(t_b)
  \end{bmatrix}$ in diskreten Zeitpunkten $\begin{bmatrix}
  t_a\\ \vdots\\ t_b
  \end{bmatrix}$ mit geeigneter Diskretisierung.
  \item Prozesssimulation\footnote{\textsc{Matlab}: $\text{\lstinline[columns=fixed]{lsim}}(\dot{x}=ax+bu,\begin{bmatrix}
  u(t_a)\\ \vdots\\u(t_b)
  \end{bmatrix},\begin{bmatrix}
  t_a\\ \vdots\\ t_b
  \end{bmatrix},x_a)$} mit gegebenen \ac{AW} $\begin{bmatrix}
  x(t_a)\\ \vdots\\x(t_b)
  \end{bmatrix}$ und Steuerfunktion.
  \item "`Rückwärtssimulation"'\footnote{\textsc{Matlab}: $\text{\lstinline[columns=fixed]{exp}}(a(\begin{bmatrix}
  t_a\\ \vdots\\ t_b
  \end{bmatrix} - t_a))Sx(t_b)$} der adjungierten Prozessgleichung
  $\begin{bmatrix} \psi(t_a)\\ \vdots\\ \psi(t_b)
  \end{bmatrix}$ aus 
  \begin{align*}
  	\Ham & = \frac12 u^2 + \psi\left(ax+bu\right)\\
  	\nabla_x\Ham & = a\psi\\
  	\dot{\Psi}(\tau) & = a\Psi(\tau)\\
  	\Psi(t_a) & = Sx(t_b), & \tau\in[t_a,t_b]\\
  	\Psi(\tau) & = e^{a(\tau -t_a)}Sx(t_b).
  \end{align*}
  $t$ läuft von $t_b$ nach $t_a$ und $\tau$ läuft von $t_a$ nach $t_b$.
  \item Aktualisierung der Steuerfunktion
  \begin{align*}
  	\begin{bmatrix}
  u(t_a)\\ \vdots\\ u(t_b)
  \end{bmatrix} & \leftarrow \begin{bmatrix}
  u(t_a)\\ \vdots\\ u(t_b)
  \end{bmatrix} - \alpha\left(\begin{bmatrix}
  u(t_a)\\ \vdots\\ u(t_b)
  \end{bmatrix} + \begin{bmatrix}
  \psi(t_a)\\ \vdots\\ \psi(t_b)
  \end{bmatrix}b \right)
  \end{align*}
  aus $\nabla_u\Ham = u+\psi b$, $\nabla_{uu}=1$ und
  \begin{align*}
  	u(t) & \leftarrow u(t) - \alpha\left(u(t) + \psi(t)b \right).
  \end{align*}
  \item Falls Abbruchbedingung erfüllt ist, dann Stopp, andernfalls gehe zu (S2).
\end{enumerate}
\end{exmp}
Es ist eine Übung unter \picref{sec:uebung_num_best_opt_lsg}{Vorgehensweise zur numerischen Bestimmung der Optimallösung} im Anhang zu finden.

\subsection{Anwendung zur Umformung von Optimierungsproblemen am Beispiel des \NoCaseChange{\acl{LQR}}-Problems}
Minimiere das Gütefunktional
\begin{align*}
	J  & = \frac12 x^T(t_b)Gx(t_b)+\frac12\int\limits_{t_a}^{t_b}\left[x^T(t)Q(t)x(t)+u^TR(t)u(t)\right]dt
\end{align*}
bei dem Prozess 
\begin{align*}
	\dot{x}(t) & = A(t)x(t)+B(t)u(t)
\end{align*}
mit den gegebenen Werten $x(t_a)=x_a$, $t_a$, $x_a$ und $t_b$, wobei der Zustandswert zur Endzeit $x(t_b)$ frei ist. Weiterhin sollen $G\ge 0$,
$Q(t)\ge 0$ (semipositiv defintit), $R(t)>0$ (positiv definit)\footnote{WEnn $R(t)$ smidefinit wäre, würde es $u$ geben, die keine Kosten erzeugen.}
und $Q(t)$, sowie $R(t)$ stetig differenzierbar sein. Der Ausgang wird berechnet mit
\begin{align*}
	y & = C x
\end{align*}
mit der Wichtung von $y$
\begin{align*}
	y^T W y & = x^T\underbrace{c^TWc}_{Q(t)}x.
\end{align*}
Es wird die Hamilton-Funktion gebildet
\begin{align*}
	\Ham & = \frac12\left(x^T(t) Q(t)x(t)+u^T(t)R(t)u(t)+\psi^T(t)\left(A(t)x(t)+B(t)u(t) \right) \right).
\end{align*}
Damit kann die kanonische Differentialgleichung und die \ac{RB}en angeben werden
\begin{align*}
	\dot{x}(t) & = \nabla_{\psi}\Ham = A(t)x(t)+B(t)u(t),\\
	\dot{\psi}(t) & = -\nabla_x\Ham = -\left(Q(t)x(t) + A^T(t)\psi(t) \right),\\
	x(t_a) & = x_a, \\
	\psi(t_b) & = \nabla_x h=G x(t_b).
\end{align*}
Die Steuerungsgleichung 
\begin{align*}
	\nabla_u\Ham & = R(t) u(t) + B^T(t)\psi(t)=0
\end{align*}
liefert
\begin{align*}
	u(t) & = -R^{-1}(t)B^T(t)\psi(t).
\end{align*}
Wir haben ein lineares homogenes Differentialgleichungssystem und $\psi(t_b)$ ist linear von $x(t_b)$ abhängig. Dies motiviert zu dem Ansatz
\begin{align*}
	\psi(t) & = X(t)x(t), & \forall t\in[t_a,t_b].
\end{align*}
Dann gilt für jedes $x(t)$
\begin{align*}
	\dot{\psi}(t) & = \dot{X}x + X\dot{x}\\
	& = \dot{X}x + X\left(Ax-BR^{-1}B^TXx \right)\\
	& = -Qx-A^TXx
\end{align*}
was auf
\begin{align*}
	\left(\dot{X} + X\left(A-BR^{-1}B^TX \right) + Q +A^TX \right)x & = 0.
\end{align*}
führt, was wiederrum die Matrix-Ricatti-Differentialgleichung
\begin{align*}
	\dot{X} & = -A^TX -XA + XBR^{-1}B^TX -Q
\end{align*}
mit der Endbedingung $x(t_b)$ liefert. Das Regelgesetz kann zu
\begin{align*}
	u(t) & = \underbrace{-R^{-1}(t)B(t)X(t)}_{=:k(t)}x(t)
\end{align*}
formuliert werden, was eine lineare zeitvariante Zustandsrückführung darstellt.

\section{Maximumprinzip von Pontryagin}
Die Aufgabe ist das Kostenfunktional
\begin{align*}
	J & = h\left(x(t_b),t_b \right) + \int\limits_{t_a}^{t_b} f_0(x(t),u(t),t)dt\rightarrow\min
\end{align*}
für den Prozess
\begin{align*}
	\dot{x}(t) & = f\left( x(t),u(t),t \right),
\end{align*}
mit $u:[t_a,t_b]\rightarrow \Omega\subset\mathbb{R}^p$ mit dem zulässigen Bereich $\Omega$, der zeitvariant, abgeschlossen und konvex ist, zu
minimieren.\\
Die \ac{AB} seien gegeben mit gegebenen $t_a$, $x_a$ mit $x(t_a)=x_a$.\\
Die \ac{EB} seien gegeben mit gegebenen oder freien $t_b$ und $z(x(t_b))=0$ mit $z:\mathbb{R}^n\rightarrow\mathbb{R}^m$, d.h. es wird Fall A
betrachtet.\\
$h$, $f_0$, $f$ und $z$ seinen stetig differenzierbar bezüglich aller Argumente. Es ist keine Beschreibung für $x(t)$ für $t\in[t_a,t_b]$ gegeben.

\subsection{Prinzip der Herleitung der notwendigen Bedingungen}
Es wird der Lagrange-Multiplikator
\begin{align*}
	\bar{J} & = \lambda_0 h\left(x(t_b),t_b \right) + \int\limits_{t_a}^{t_b}\left[\lambda_0 f_0(x(t),u(t),t) + \dot{\psi}^T(t)\left(f(x(t),u(t),t) -
	\dot{x}(t) \right) \right]dt\\
	&\quad + \lambda_a^T\left\{x_a - x(t_a) \right\} + \lambda_b^T z(x(t_b))
\end{align*}
eingeführt. Weiter wird die Hamilton-Funktion $\Ham:\mathbb{R}^n\times\Omega\times\mathbb{R}^n\times\{0,1\}\times[t_a,t_b]\rightarrow\mathbb{R}^1$
\begin{align*}
	\Ham \left(x(t),u(t),\psi(t),\lambda_0,t \right) & = \lambda_0 f_0\left(x(t),u(t),t \right) + \psi^T(t)f\left(x(t),u(t),t \right). 
\end{align*}
definiert. Analog zu \secref{sec:kap_2_pr_herl_not_bed} werden die Variationen $\zeta(t)=\zeta^{\ast}(t)+\epsilon\tilde{\zeta}(t)$ mit
$\zeta\in\{x,u,\psi \}$ und $\zeta=\zeta^{\ast}+\epsilon\tilde{\zeta}$ mit $\zeta\in\{x(t_a),\lambda_a, x(t_b), \lambda_b, t_b\}$ eingeführt. Aufgrund
der Beschränkung $u(t)\in\Omega$ erfolgt die Herleitung der notwendigen Variantionen für die Extremstellen aus $\left.\frac{\td F}{\td
\epsilon}\right|_{\epsilon=0}\geq 0$, anstelle von $\left.\frac{\td F}{\td \epsilon}\right|_{\epsilon=0} = 0$. Aus 
\begin{align*}
	\left.\frac{\td F}{\td \epsilon}\right|_{\epsilon=0} & = \left[\lambda_0\frac{\d h}{\d t}+\Ham \right]_{t_b}\tilde{t}_b +
	\int\limits_{t_a}^{t_b}\left[\left(\frac{\d \Ham}{\d x}+\dot{\psi}^T \right)\tilde{x} + \frac{\d \Ham}{\d u}\tilde{u} + \left(\frac{\d \Ham}{\d \psi}
	-\dot{x}^T \right)\tilde{\psi}\right]dt\\
	& \quad + \ldots \geq 0
\end{align*}
erhält man speziell für $\tilde{u}\neq 0$, $\tilde{x}=0$, $\tilde{\psi}=0$, $\ldots$ die notwendige Bedingung $\int\limits_{t_a}^{t_b}\frac{\d\Ham}{\d
u}\tilde{u}\geq 0$ für alle zulässigen Variationen und hieraus kann man folgern
\begin{align*}
0 & \leq \frac{\d \Ham}{\d u}\left(x^{\ast}(t), u^{\ast}(t), \psi^{\ast}(t),\lambda_0^{\ast},t \right)\tilde{u}(t)
\end{align*}
mit $\forall \tilde{u}(t)\in dZ(\Omega,u^{\ast}(t))$ und $\forall t\in[t_a,t_b]$. Dies ist eine notwendige Bedingung für ein (lokales) Minimum von
\begin{align*}
	u(t)\in\Omega & \mapsto \Ham\left(x^{\ast}(t), u(t), \psi^{\ast}(t),\lambda_0^{\ast},t \right) .
\end{align*}
Die übrigen Variationen sind unbeschränkte Variationen und führen auf die gleichen notwendigen Bedingungen wie in \secref{sec:kap_2_pr_herl_not_bed}.
\begin{satz}[Pontryaginschs Minimumprinzip]
Falls $u^{\ast}:[t_a,t_b]\rightarrow\Omega$ optimal ist, so gibt es einen Vektor $\begin{bmatrix}
\lambda_0^{\ast}\\ \psi^{\ast}(t_b)
\end{bmatrix}\neq 0\in\mathbb{R}^{n+1}$ mit $\lambda_0^{\ast}=\left\{\begin{array}{cl}
1 & \text{im regulären Fall}\\
0 & \text{im singulären Fall}
\end{array} \right.$, so dass
\begin{enumerate}[label=(\arabic*)]
  \item gilt
  \begin{align*}
  	\dot{x}^{\ast}(t) & = \left.\nabla_{\psi}\Ham\right|_{\ast} = f\left(x^{\ast}(t),u^{\ast}(t),t \right),\\
  	\dot{\psi}^{\ast}(t) & = \left.-\nabla_x\Ham\right|_{\ast}=-\lambda_0^{\ast}\nabla_xf_0\left(x^{\ast}(t),u^{\ast}(t),t \right)-\left[\frac{\d
  	f}{\d x}\left(x^{\ast}(t),u^{\ast}(t),t \right) \right]^T\psi^{\ast}(t),\\
  	x^{\ast}(t_a) & = x_a,\\
  	z(x^{\ast}(t_a)) & = 0,\\
  	\psi^{\ast}(t_b) & = \lambda_0^{\ast}\nabla_xh\left(x^{\ast}(t_b),t_b \right)+\left[\frac{\d z}{\d x}\left(x^{\ast}(t_b) \right)
  	\right]^T\lambda_b.
  \end{align*}
  \item gilt
  \begin{align}
  	\Ham\left(x^{\ast}(t),u^{\ast}(t),\psi^{\ast}(t),\lambda_0^{\ast},t \right) & \leq
  	\Ham\left(x^{\ast}(t),u(t),\psi^{\ast}(t),\lambda_0^{\ast},t \right)	\label{eqn:kap_2_Pontryagin_min}
  \end{align}
  mit $\forall u\in\Omega$ und $\forall t\in[t_a,t_b]$, d.h. die Funkeion
  $u\in\Omega\mapsto\Ham\left(x^{\ast}(t),u^{\ast}(t),\psi^{\ast}(t),\lambda_0^{\ast},t \right)$ hat an der Stelle $u^{\ast}(t)$ ein globales Minimum.
  \item gilt falls $t_b$ frei ist, so muss zusätzlich gelten
  \begin{align*}
  	\Ham\left(x^{\ast}(t_b),u^{\ast}(t_b),\psi^{\ast}(t_b),\lambda_0^{\ast},t_b \right) & = -\lambda_0^{\ast}\frac{\d h}{\d t}\left(x^{\ast}(t_b),t_b
  	\right)
  \end{align*}
\end{enumerate}
\end{satz}

\begin{defi}
Die Lösung des Steuerungsproblems heisst singulär, falls
\begin{enumerate}[label=(\Roman*)]
  \item $\lambda_0=0$ oder
  \item $H\neq H(u)$ für $t\in[t_1,t_2]\subseteq[t_a,t_b]$ mit $t_1<t_2$, d.h. es gibt ein Intervall mit Lösungen größer Null auf dem $H$ keine
  explizite Funktion der Steuergröße ist.
\end{enumerate}
\end{defi}

\begin{remark}[Zum Fall (I)]
Im Fal $\lambda_0=0$ ist die Zielfunktion für die Lösung nicht relevant, da die optimale Lösung bereits durch die \ac{NB} festgelegt ist. Das heisst,
der geforderte Endzustand liegt auf dem Rand der Menge aller Zustandsvektoren, die durch die Zeitpunkte $t_b$ erreichtbar sind. 
\end{remark}

\begin{exmp}
Minimiere $J = \int\limits_0^1 u(t)dt$ für den Prozess $\dot{x}=u(t)^2$ unter der \ac{NB} $x(0)=x(1)=0$. Offenbar erfüllt nur $u\equiv 0$ die \ac{NB}
und ist daher optimal. Mit der Hamilton-Funktion
\begin{align*}
	\Ham\left(x,u,\psi,\lambda_0,t \right) & = \lambda_0u + \psi u^2
\end{align*}
gilt
\begin{align*}
	0 & = \Ham_u = \lambda_0 2\psi u
\end{align*}
und
\begin{align*}
	\dot{\psi}& = -\Ham_x=0.
\end{align*} 
Damit ist $\psi=const$ und damit ein unbeschränktes Problem. Falls $\psi = 0$, so gilt auch $\lambda_0=0$. Angenommen $\psi\neq 0$, so ist
$u=-\frac{\lambda_0}{2\psi}$. Falls $\lambda_0\neq 0$ ist, so wäre $x(1)>0$, d.h. diese $u$ wäre nicht zulässig. Also muss $\lambda_0=0$ gelten.
\end{exmp}

\begin{remark}[Zum Fall (II)]
Meist trifft dieser Fall auf, wenn $\Ham$ eine affine Funktion ist, d.h. 
\begin{align*}
	\Ham & = g\left(x(t),\psi(t),\lambda_0,t \right) + \mu\left(x(t),\psi(t),\lambda_0,t \right)u(t)
\end{align*}
ist und $\mu\left(x^{\ast}(t),\psi^{\ast}(t),\lambda_0^{\ast}(t),t \right)$ für alle $t\in[t_1,t_2]$ verschwindet. Jedes zulässige $u(t)$ ist genau
dann eine Lösung von \eqnref{eqn:kap_2_Pontryagin_min}. Die optimale Lösung muss "`anderweitig"' gefunden werden, z.B. aus $\mu\equiv 0$ auf
$[t_1,t_2]$ folgt $\dot{\mu}\equiv 0$, $\ddot{\mu}\equiv 0$, $\ldots$. Es wird solange differenziert, bis $u$ explizit auftaucht, d.h. 
\begin{align*}
	\dot{\mu} & = \frac{\d \mu}{\d x}\dot{x}+\frac{\d \mu}{\d \psi}\dot{\psi}+\frac{\d\mu}{\d t} = 0
\end{align*}
liefert die Bedingungen für $u$, ansonsten kann $\dot{\mu}=0$ versucht werden.
\end{remark}

\begin{exmp}[Zeitoptimale Steuerung eines Doppelintegrators]\label{exmp:kap_2_zeitopt_dint}
Der Prozess 
\begin{align*}
	\dot{x}(t) & = \begin{bmatrix}
	0 &  1\\ 0 & 0
	\end{bmatrix}x(t) + \begin{bmatrix}
	0\\ 1
	\end{bmatrix}u(t)
\end{align*}
mit dem gegebenen Anfangszustand $x_0=\begin{bmatrix}
s_a\\ v_a
\end{bmatrix}$ soll durch die Steuerungfunktion $u:[0,t_b]\rightarrow \Omega= [-a_{max},a_{max}]$ mit $a_{max}>0$ so in den Endzustand
$x(t_b)=\begin{bmatrix}
s_b\\ v_b
\end{bmatrix}$ überführt werden, dass $J =\int\limits_0^{t_b}dt=t_b$ minimiert wird\footnote{Integration von $f_0(x,u,t)=1$ oder von $h(x(t_b),t_b)$
führt beides zum selben Ergebnis.}. Es wird die Hamilton Funktion
\begin{align*}
	\Ham & = \lambda_0 + \psi_1(t)x_2(t) + \psi_2(t)u(t)
\end{align*}
gebildet. Nach Pontryagin muss ein Vektor 
\begin{align}
	\begin{bmatrix}
	\lambda_0^{\ast}\\ \psi_1^{\ast}(t_b)\\ \psi_2^{\ast}(t_b)
	\end{bmatrix} & \neq 0 \in\mathbb{R}^3	\label{eqn:kap_2_bsp_1_vektor_pont}
\end{align}
existieren, so dass folgenden Bedingungen erfüllt sind
\begin{enumerate}[label=(\alph*)]
  \item $\dot{x}_1^{\ast}(t)=x_2^{\ast}(t)$, $\dot{x}_2^{\ast}(t)=u^{\ast}(t)$, $\dot{\psi}_1^{\ast}(t)=\left.-\frac{\d \Ham}{\d
  x_1}\right|_{\ast}=0$, $\dot{\psi}_2^{\ast}(t)=\left.-\frac{\d \Ham}{\d x_2}\right|_{\ast}=-\psi_1^{\ast}(t)$, $x_1^{\ast}(0)=s_a$,
  $x_2^{\ast}(0)=v_a$, $x_1^{\ast}(t_b)=s_b$, $x_2^{\ast}(t_b)=v_b$,
  \item $\psi_2^{\ast}(t)u^{\ast}(t)\leq\psi_2^{\ast}(t)u$ mit $\forall u\in\Omega$ und $\forall t\in[0,t_b]$,
  \item $\Ham(t_b)= \lambda_0^{\ast}+\psi_1^{\ast}(t_b)x_2^{\ast}(t_b)+\psi_2^{\ast}(t_b)u^{\ast}(t_b)=0$.
\end{enumerate}
(b) liefert 
\begin{align*}
u^{\ast}(t) & = \left\{\begin{array}{cl}
a_{max} & \text{für }\psi_2^{\ast}(t) < 0\\
u\in[-a_{max},a_{max}] & \text{für }\psi_2^{\ast}(t) = 0\\
-a_{max} & \text{für }\psi_2^{\ast}(t) > 0
\end{array} \right.
\end{align*}. In den Zeitpunkten für die $\psi_2^{\ast}(t)=0$ gilt, minimiert jedes $u(t)\in\Omega$ die Hamilton-Funktion. Es ist kein
singuläres Problem, da $\psi_2^{\ast}$ nur isolierte Nullstellen und genauer in $[0,t_b]$ sogar nur höchstens eine Nullstelle
existiert.\begin{proof}
Da $\dot{\psi}_1(t)=0$ ist $\psi_1^{\ast}(t)=c_1^{\ast}$ konstant und wegen $\dot{\psi}_2^{\ast}(t)=-\psi_1^{\ast}(t)$ ist
$\psi_2^{\ast}=-c_1^{\ast}t+c_2^{\ast}$. Angenommen es ist $\psi_2^{\ast}=0$ für $t\in[t_1,t_2]$ mit $t_2>t_1$. Dann ist $c_1^{\ast}=c_2^{\ast}=0$ und
damit $\psi_1^{\ast}(t)=\psi_2^{\ast}(t)=0$ für $t\in[0,t_b]$ und wegen (c) wäre $\lambda_0^{\ast}=0$. Damit wird es zu
\eqnref{eqn:kap_2_bsp_1_vektor_pont}.
\end{proof}
Änderung von Werten der Steuergrößen auf abzählbar viele Punkte beieinflusst die der Prozessgleichung nicht, da können wir 
\begin{align*}
	u(t) & = -a_{max}\sgn\left(\psi_2^{\ast}(t) \right) = \left\{\begin{array}{cl}
	a_{max} & \text{für }\psi_2^{\ast}(t) < 0\\
	0 & \text{für }\psi_2^{\ast}(t) = 0\\
	-a_{max} & \text{für }\psi_2^{\ast}(t) > 0
	\end{array} \right.
\end{align*}
setzen. Da $\psi_2^{\ast}(t)$ höchstens eine Nullstelle besitzt, ist $u^{\ast}(t)$ stückweise konstant und hat höchstens einen Sattelpunkt
(Strukturaussage, vgl. \figref{fig:kap_2_bsp_1_uast_pont}). $\psi_2$ heisst Schaltfunktion.
\begin{figure}[htb]
	\centering
	\input{tikz/dummy}
	\caption{Verlauf von $u^{\ast}(t)$}
	\label{fig:kap_2_bsp_1_uast_pont}
\end{figure}
Damit hat man drei freie Parameter $c_1$, $c_2$ und $t_b$ bzw. $u(0)$, $t_s$ und $t_b$ zur Anpassung an die Randbedingungen. Für ein konstantes
$u^{\ast}\equiv a$ erhält man für $t\geq \tau$ die Zustandstrajektorie
\begin{align*}
	x_2^{\ast}(t)&=x_2^{\ast}(\tau)+a(t-\tau)
\end{align*} und für
\begin{align*}
	x_1^{\ast}(t)&=x_1^{\ast}(\tau)+x_2^{\ast}(\tau)(t-\tau)+\frac{a}{2}(t-\tau)^2
\end{align*} 
oder in der implizierten Form 
\begin{align*}
	x_1^{\ast}(t)-x_1^{\ast}(\tau) & = \frac{x_2^{\ast}(\tau)}{a}\left(x_2^{\ast}(t)-x_2^{\ast}(\tau) \right) +
	\frac{1}{2a}\left(x_2^{\ast}(t)-x_2^{\ast}(\tau) \right)^2.
\end{align*}
Dies sind Parabeln durch $(x_1^{\ast}(\tau),x_2^{\ast}(\tau))$ mit der Achse gleich der $x_1$-Achse, offen nach rechts für $a>0$ und offen nach links
für $a<0$, vgl. \figref{fig:kap_2_bsp_1_zustands_pont}.
\begin{figure}[htb]
	\centering
	\input{tikz/dummy}
	\caption{Darstellung der Zustandstrajektorien für konstantes $u^{\ast}\equiv a$}
	\label{fig:kap_2_bsp_1_zustands_pont}
\end{figure}
Man erhält, wie in Abbildung \figref{fig:kap_2_bsp_1_zustands_u_pont} dargestellt,
\begin{align*}
	u^{\ast} & = \left\{\begin{array}{cl}
	+a_{max} & \text{falls $x(t)$ auf grün oder links von grün oder links von rot}\\
	-a_{max} & sonst
	\end{array} \right. .
\end{align*}
\begin{figure}[htb]
	\centering
	\input{tikz/dummy}
	\caption{Darstellung der Zustandstrajektorien für zeitoptimale Regelung eines Doppelintegrators}
	\label{fig:kap_2_bsp_1_zustands_u_pont}
\end{figure}
\end{exmp}
\begin{exmp}[Verbrauchsoptimale Steuerung eines Doppelintegrators]
Der Prozess
\begin{align*}
	\dot{x}(t) & = \begin{bmatrix}
	0 & 1 \\ 0 & 0
	\end{bmatrix}x(t) + \begin{bmatrix}
	0\\ 1
	\end{bmatrix}u(t)
\end{align*}
mit gegebenen Anfangszustand $x_0=\begin{bmatrix}
s_a\\ v_a
\end{bmatrix}$ soll durch die Steuerfunktion $u:[0,t_b]\rightarrow\Omega=[-a_{max},a_{max}]$ mit $a_{max}>0$ in den Endzustand $x(t_b)=\begin{bmatrix}
s_b\\ v_b
\end{bmatrix}$ überführt werden, so dass $J=\int\limits_0^{t_b}|u(t)|dt$ mit vorgebenen $t_b$ minimiert wird. Es wird die Hamilton-Funktion
\begin{align*}
	\Ham & = \lambda_0|u(t)|+\psi_1(t)x_2(t)+\psi_2(t)u(t)
\end{align*}
gebildet. Nach Pontryagin muss ein Vektor 
\begin{align*}
	\begin{bmatrix}
	\lambda_0^{\ast}\\ \psi_1^{\ast}(t_b)\\ \psi_2^{\ast}(t_b)
	\end{bmatrix} & \neq 0 \in\mathbb{R}^3
\end{align*}
existieren, so dass folgenden Bedingungen erfüllt sind
\begin{enumerate}[label=(\alph*)]
  \item $\dot{x}_1^{\ast}(t)=x_2^{\ast}(t)$, $\dot{x}_2^{\ast}(t)=u^{\ast}(t)$, $\dot{\psi}_1^{\ast}(t)=\left.-\frac{\d \Ham}{\d
  x_1}\right|_{\ast}=0$, $\dot{\psi}_2^{\ast}(t)=\left.-\frac{\d \Ham}{\d x_2}\right|_{\ast}=-\psi_1^{\ast}(t)$, $x_1^{\ast}(0)=s_a$,
  $x_2^{\ast}(0)=v_a$, $x_1^{\ast}(t_b)=s_b$, $x_2^{\ast}(t_b)=v_b$,
  \item $\lambda_0^{\ast}\left|u^{\ast}(t) \right|+\psi_2^{\ast}(t)u^{\ast}(t)\leq \lambda_0^{\ast}\left|u
  \right|+\psi_2^{\ast}(t)u $ mit $\forall u\in\Omega$ und $\forall t\in[0,t_b]$,
  \item entfällt, da $t_b$ fest vorgegeben ist.
\end{enumerate}
Wie in \exmpref{exmp:kap_2_zeitopt_dint} ist $\psi_2^{\ast}(t)=-c_1^{\ast}t+c_2^{\ast}$ eine affine Funktion.\\ 
Für $\lambda_0^{\ast}=0$, entspricht dem singulären Fall, liefert (b) analog zu \exmpref{exmp:kap_2_zeitopt_dint}, d.h. $\psi_2\equiv 0$ ist
ausgeschlossen, die optimale Steuerfunktion
\begin{align*}
	u^{\ast}(t) & = \left\{\begin{array}{cl}
	a_{max} & \text{für }\psi_2^{\ast}(t) < 0\\
	0 & \text{für }\psi_2^{\ast}(t) = 0\\
	-a_{max} & \text{für }\psi_2^{\ast}(t) > 0
	\end{array} \right. .
\end{align*}
$\psi_2$ ist eine affine Funktion mit höchstens einer Nullstelle.

Für $\lambda_0=1$ ist $\min\limits_{u\in[-a_{max},a_{max}]}|u|+\psi_2 u$ zu lösen.
\begin{enumerate}
  \item Für $u\in[0,a_{max}]$ erhalten wir die Zielfunktion $(1+\psi_2)u$ und
  \begin{align*}
  	u^{\ast}(t) & = \left\{\begin{array}{cl}
  	0 & \text{für }\psi_2^{\ast}(t) > -1\\
	u\in[0,a_{max}] & \text{für }\psi_2^{\ast}(t) = -1\\
	a_{max} & \text{für }\psi_2^{\ast}(t) < -1
  	\end{array} \right. .
  \end{align*}
  \item Für $u\in[-a_{max},0]$ erhalten wir die Zielfunktion $(\psi_2-1)u$ und
  \begin{align*}
  u^{\ast}(t) & = \left\{\begin{array}{cl}
  	-a_{max} & \text{für }\psi_2^{\ast}(t) > 1\\
	u\in[-a_{max},0] & \text{für }\psi_2^{\ast}(t) = 1\\
	0 & \text{für }\psi_2^{\ast}(t) < 1
  \end{array} \right. .
  \end{align*}
\end{enumerate}
Also ist 
\begin{align}
u^{\ast}(t) & = \left\{\begin{array}{cl}
a_{max} & \text{für }\psi_2^{\ast}(t) < -1\\
u\in[0,a_{max}] & \text{für }\psi_2^{\ast}(t) = -1\\
0 & \text{für }\psi_2^{\ast}(t) \in(-1,1)\\
u\in[-a_{max},0] & \text{für }\psi_2^{\ast}(t) = 1\\
-a_{max} & \text{für }\psi_2^{\ast}(t) > 1
\end{array} \right. . \label{eqn:kap_2_verbrau_opt_u}
\end{align}
$\psi_2(t)$ ist eine affine Funktion. $c_1=0$ ist möglich. Die Ergebnisse können wie folgt interpretiert werden
\begin{itemize}
  \item Der Fall $\lambda_0^{\ast}=0$, singulärer Fall, tritt nur auf, wenn das vorgegebene $t_b$ gleich dem Minimalwert $t_{b,min}$ des zeitoptimalen
  Problems ist, d.h. die Lösung ist allein durch die \ac{NB} bestimmt.  
  \item Im Fall $\lambda_0^{\ast}=1$ gibt es spezielle Situationen falls $c_1^{\ast}=0$ ist. Insbesondere kann $\psi_2^{\ast}\equiv 1$ oder
  $\psi_2^{\ast}\equiv -1$ notwendig sein, nämlich falls der Endzustand allein mit entweder $u^{\ast}(t)\in[0,a_{max}]$ oder mit
  $u^{\ast}(t)\in[-a_{max},0]$ erreichbar ist. Dann gibt es unendlich viele optimale Lösungen.\\
  Am Beispiel mit konkreten Werten für $t_b=3$, $a_{max}=1$, $v_a=1$, $s_a=0$, $v_b=0$ und $s_b=\frac32$ ist der Endwert allein durch Abbremsen
  erreichbar. In diesem Fall sind Trajektorien bei denen beschleunigt wird nicht optimal. Wir betrachten also nur Trajektorien die in
  \eqnref{eqn:kap_2_verbrau_opt_u} in den Zeilen 3 bis 5 auftauchen. Würde man $c_1^{\ast}=0$ nicht betrachten und damit $\psi_2^{\ast}\equiv
  1$ ausschliessen, so würde $v(t_b)=0$ lediglich von den Trajektorien (1) und (2) aus \figref{fig:kap_2_verbrau_opt_trajs} erfüllt. Diese erfüllen
  aber $s(t_b)=s_b$ nicht und sind daher nicht zulässig.\\
  Lässt man $c_1^{\ast}=0$ und damit $\psi_2^{\ast}\equiv 1$ zu, so wird auch Trajektorie (3) aus \figref{fig:kap_2_verbrau_opt_trajs} zugelassen.
  Diese erfüllt die \ac{RB} und minimiert die Zielfunktion, d.h. es ist eine optimale Lösung. WEiter stellt man fest, dass jede Trajektorie, welche die \ac{RB} erfüllt und für die
  $u(t)=[-a_{max},0]$ gilt, ist optimal, wie bspw. Trajektorie (4) in \figref{fig:kap_2_verbrau_opt_trajs}.
  \begin{figure}[htb]
	\centering
	\input{tikz/dummy}
	\caption{Mögliche Zustandstrajektorien für $u^{\ast}(t)$}
	\label{fig:kap_2_verbrau_opt_trajs}
  \end{figure}
  \item Im "`Normalfall"' ist $t_b>t_{b,min}$, d.h. $\lambda_0^{\ast}=1$, und $c_1^{\ast}\neq 0$ und damit ist
  \begin{align*}
  	u^{\ast}(t) & = \left\{\begin{array}{cl}
  	a_{max}		& \text{für }\psi_2^{\ast}(t) <-1\\
  	0			& \text{für }\psi_2^{\ast}(t) \in(-1,1)\\
  	-a_{max}	& \text{für }\psi_2^{\ast}(t) >1
  	\end{array} \right. .
  \end{align*}
  Es tritt maximal eine Umschaltung von $-a_{max}$ nach $0$ und von $0$ nach $a_{max}$ auf bzw. andersherum. Die Zustandstrajektorie besteht aus
  maximal zwei Parabelabschnitten und dazwischen einer Strecke parallel zur $x_1$-Achse, vgl. \figref{fig:kap_2_bsp_2_zustands_u_pont}.
\end{itemize}
\begin{figure}[htb]
	\centering
	\input{tikz/dummy}
	\caption{Darstellung der Zustandstrajektorien für verbrauchsoptimale Regelung eines Doppelintegrators}
	\label{fig:kap_2_bsp_2_zustands_u_pont}
\end{figure}
\end{exmp}
\begin{remark}
Weitere Beispiele sind mit Zustandsbeshränkung sind im \cite{geering2007optimal} zu finden.
\end{remark}
\begin{exmp}[Anwendung des Satz von Feldbaum]
Sei $\dot{x}=Ax+bu$ steuerbar, stabil mit ausschliesslich reellen Eigenwerte und der Eingang beschränkt mit
$u(t)\in\left[\underline{u},\overline{u}\right]\subset\mathbb{R}^1$ und mit $x(t)\in\mathbb{R}^n$. Dann hat eine zeitoptimale Steuerung zur
Überführung von $x_a$ nach $x_b$, sofern diese existiert, die Form $u^{\ast}(t)\in\{\underline{u},\overline{u}\}$, $t\in[t_a,t_b]$, mit maximal $n-1$
Umschaltpunkten. \\
Seien vereinfachend $t_a=0$, symmetrische Steuergrößenbeschränkung $\underline{u}=-u_{max}$, $\overline{u}=u_{max}>0$ und $A$ habe ausschliesslich
einfache Eigenwerte. Es gelten
\begin{align*}
	x(t) & = e^{At}x_a+\int\limits_0^t e^{A(t-\tau)}bu(\tau)d\tau
\end{align*}
und
\begin{align*}
	u(t) & = (-1)^{i-1}\alpha u_{max}
\end{align*}
mit $i=1,\ldots,n$, $t\in[t_{i-1},t_i]$, $\alpha\in\{-1,1\}$, $t_0=t_a$ und $t_n=t_b$. Dann ist
\begin{align*}
	x(t_b) & = x_b = e^{At_n}x_a + \alpha u_{max}\sum\limits_{i=1}^{n}(-1)^{i-1}\int\limits_{t_{i-1}}^{t_i}e^{A(t_n-\tau)}bd\tau
\end{align*}
und
\begin{align*}
	e^{-At_n}x_b-x_a & = \alpha u_{max}\sum\limits_{i=1}^n(-1)^{i-1}\underbrace{\int\limits_{t_{i-1}}^{t_i}e^{-A\tau}bd\tau }_{=w(t_i)-w(t_{i-1})}.
\end{align*}
Mit 
\begin{align*}
	A & = V\Lambda V^{-1},\\
	e^{At} & = V e^{\Lambda} V^{-1}= V\begin{bmatrix}
	e^{\lambda_1 t}	& 			&\\
					& \ddots 	&\\
					&			& e^{\lambda_n t}
	\end{bmatrix}V^{-1},\\
	\int\limits_{a}^{b}e^{A\tau}d\tau & = V\int\limits_a^b e^{\Lambda \tau}\d\tau = V\begin{bmatrix}
	\int\limits_a^b e^{\lambda_1 \tau}d\tau	& 			&\\
					& \ddots 	&\\
					&			& \int\limits_a^b e^{\lambda_n \tau}d\tau
	\end{bmatrix}V^{-1},\\
	\int\limits_a^b e^{\lambda_k \tau}d\tau & = \frac{1}{\lambda_k}\left(e^{\lambda_k b}-e^{\lambda_k a} \right)
\end{align*}
für $k=1,\ldots,n$ lässt sich die Stannfunktion $w(.)$ darstellen.\\
Man erhält das nichtlineare Gleichungssystem
\begin{align*}
	\frac{1}{\alpha u_{max}}\left(e^{-At_n}x_b-x_a \right) & = -w(0) + 2 w(t_1) - 2 w(t_2) + \ldots +(-1)^{n-1}w(t_n)
\end{align*}
mit $n$ Gleichungen und $n$ Unbekannten $t_1,\ldots,t_n$. Das Gleichungssystem hat entweder für $\alpha = 1$ oder für $\alpha = -1$ eine Lösung.
\begin{remark}
Verfahren ist auf Systeme mit $u(t)\in\mathbb{R}^n$ erweiterbar. Für instabile $A$ muss es keine zulässige Trajektorie geben. Allerdings muss es auch
nicht für stabile $A$ eine zulässige Trajektorie geben, bspw. $a=-1$, $b=1$, $u(t)\in[-1,1]$ und $x_b=2$.\\
Numerische Berechnung weniger Schaltzeitpunkte, z.B. \textsc{Newton}-Verfahren, ist unter anderem effizienter als Zeitdiskretisierung des Problems und
der direkten numerischen Lösung.
\end{remark}
\begin{figure}[htb]
	\centering
	\input{tikz/dummy}
	\caption{Beispielhafter Verlauf von $u(t)$ für $\alpha=1$}
	\label{fig:kap_2_bsp_2_zustands_u_pont}
\end{figure}
\end{exmp}
