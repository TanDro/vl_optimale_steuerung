\chapter{Klassische Verfahren zur optimalen Steuerung}
\section{Grundproblem der Variationsrechnung}
\label{sec:kap_2_grundproblem}
Die Aufgabe besteht im Auffinden einer stetig differenzierbaren Funktion $x:[t_0,t_e]\rightarrow\mathbb{R}$ mit den Randbedingungen $x(t_0)=x_0$, $x(t_e)=x_e$, so dass ein
Gütefunktional $J=\int\limits_{t_0}^{t_e}f(t,x,\dot{x}) dt$ minimal wird.

Mit der Vorgehensweise von Euler wird angenommen, man hätte eine optimale Lösung $x^{\ast}$ gefunden. Konstruiere eine einparametrige Schar von Vergleichskurven
$x(t)=x^{\ast}+\epsilon\tilde{x}(t)$, wobei $\epsilon\in(-\epsilon_0,+\epsilon_0)$ ein Parameter ($\epsilon>0$ gegeben) und $\tilde{x}$ eine gegebene, stetig differenzierbare Funktion
mit $\tilde{x}(t_0)=0$, $\tilde{x}(t_e)=0$ ist.
\begin{figure}[htb]
	\centering
	\input{tikz/dummy}
	\caption{Vorgehensweise von Euler}
	\label{fig:kap_2_vorg_euler}
\end{figure}
Die Funktion $\delta x^{\ast}:= \epsilon\tilde{x}$ heisst Variation von $x^{\ast}$ und das einsetzen in $J$ liefert 
\begin{align*}
	F(\epsilon) & := \int\limits_{t_0}^{t_e}f(t,x^{\ast}(t)+\epsilon\tilde{x}(t),\dot{x}^{\ast}(t)+\epsilon\dot{\tilde{x}}(t))dt.
\end{align*}
Sei $f$ zweifach stetig differenzierbar. Die Funktion $F:(-\epsilon_0,+\epsilon_0)\rightarrow\mathbb{R}$ hat für $\epsilon=0$ ein Minimum, also muss gelten
\begin{align*}
	\left.\frac{\td F}{\td \epsilon}\right|_{\epsilon_0} & = \int\limits_{t_0}^{t_e}\left[\frac{\td f}{\td x}\tilde{x}(t)+\frac{\d
	f}{\td\dot{x}}\dot{\tilde{x}}(t) \right]dt = 0.
\end{align*}
Mit partieller Integration 
\begin{align*}
	\int\limits_{t_0}^{t_e}\underbrace{\frac{\td F}{\td \dot{x}}\dot{\tilde{x}}(t)}_{u\cdot v'}dt & = \bigg[\underbrace{\frac{\d
	F}{\td\dot{x}}\tilde{x}}_{u\cdot v}\bigg]_{t=t_0}^{t=t_e}-\int\limits_{t_0}^{t_e} \underbrace{\frac{\td}{\td t}\frac{\td
	F}{\partial\dot{x}}\tilde{x}(t)}_{u'\cdot v}dt
\end{align*}
ergibt sich
\begin{align*}
	\int\limits_{t_0}^{t_e}\left[\frac{\td F}{\td x}-\frac{\td}{\td t}\frac{\td F}{\td\dot{x}} \right]\tilde{x}(t)dt & = 0
\end{align*}
und da $\tilde{x}$ (bis auf die Randwerte) beliebig ist, muss 
\begin{align}
	\frac{\td F}{\td x}-\frac{\td}{\td t}\frac{\td F}{\td\dot{x}} & = 0 \label{eqn:kap_2_euler_lag_dgl}
\end{align}
gelten.
\begin{remark}{Fundamentallemma der Variationsrechnung}
Sei $G:\left[a,b \right]\rightarrow\mathbb{R}^1$ stetig und gelte $\int\limits_a^b G(t)v(t)dt=0$ für alle stetig differenzierbaren Funktionen $v$ mit
$v(a)=v(b)=0$. Dann gilt $G(t)=0\forall t\in\left[a,b \right]$.
\begin{figure}[htb]
	\centering
	\input{tikz/dummy}
	\caption{Darstellung Fundamentallemma der Variationsrechnung}
	\label{fig:kap_2_fundlemma_var}
\end{figure}
\end{remark}
Dies ist eine gewöhnliche Differentialgleichung 2. Ordnung mit der Lösung $x=x(t,c_1,c_2)$. Eine Anappsung an die Randbedingungen $x(t_0,c_1,c_2)=x_0$
und $x(t_e,c_1,c_2)=x_e$ liefert $c_1$, $c_2$.
\begin{exmp}
Gegeben sind $P_0=(t_0,x_0)$ und $P_e=(t_e,x_e)$ in der Ebene. Gesucht ist die kürzeste Verbindung zwischen $P_0$ und $P_e$. Ein Bogenelement ist
beschrieben durch 
\begin{align*}
	ds^2 & = dt^2 + dx^2 = \left(1+\dot{x}^2 \right)dt^2
\end{align*}
und zu minimierende Bogenlänge, der durch $s:t\in\left[t_0,t_e \right]\mapsto \begin{bmatrix}
t\\ x(t)
\end{bmatrix}$ parametrisieirte Kurve liefert
\begin{align*}
	J  & = \int\limits_{P_0}^{P_e}ds=\int\limits_{t_0}^{t_e}\underbrace{\sqrt{1+\dot{x}^2}}_{f(t,x,\dot{x})}dt.
\end{align*}
Wegen $f_x=0$, $f_{\dot{x}}=\frac{\dot{x}}{\sqrt{1+\dot{x}^2}}$ wird aus \eqnref{eqn:kap_2_euler_lag_dgl} 
\begin{align*}
	\frac{\td}{\td t}\frac{\dot{x}}{\sqrt{1+\dot{x}^2}} & = 0,
\end{align*}
also $\frac{\dot{x}}{\sqrt{q+\dot{x}^2}}=C$ mit der Integrationskonstante $C$. Wegen $\dot{x}=c\sqrt{\frac{1}{1-c^2}}$ gibt es $c_1$ und $c_2$, so
dass $x(t)=c_1 t+c_2$. Anpassung an die \ac{RB} liefert Geradengleichung durch $P_0$ und $P_e$.
\end{exmp}
\section{Formulierung des Optimierungsproblems und Lösung}
Ausgehend vom Kostenfunktional
\begin{align*}
	J & = h\left(x(t_b),t_b \right) + \int\limits_{t_a}^{t_b}f_0\left(x(t),u(t),t \right)dt\rightarrow \min!
\end{align*}
kann der Prozess, die \ac{AB} und die \ac{EB} definiert werden\\
\begin{tabular}{ll}
Prozess: & $\dot{x}(t)=f\left(x(t),u(t),t \right)$\\
\ac{AB}: & $x(t_a)=x_a$ mit gegebenen $t_a$ und $x_a\in\mathbb{R}^n$\\
\ac{EB}: & mit $t_b$ frei und/oder $t_b$ gegeben:\\
		 & Fall A: $z\left(x(t_b) \right)=0$ mit gegebenen $z:\mathbb{R}^n\rightarrow\mathbb{R}^m$\\
		 & Fall B: $x(t_b)=x_b$ mit geg. $x_b\Leftrightarrow z(x(t_b)):=x(t_b)-x_b=0$\\
		 & Fall C: $x(t_b)$ frei, d.h. $z\equiv 0$ 
\end{tabular}
$h$, $f_0$, $f$, $z$ sind stetig differenzierbar bezüglich aller Argumente. Es gibt keine Beschränkung von $u(t)$ und $x(t)$ für $t\in\left(t_a, t_b
\right)$.\\
Falls $t_b$ gegeben ist und Fall B besteht, so ist $h(x(t_b),t_b)$ fest und kann aus Kostenfunktional gestrichen werden.

\subsection{Prinzip der Herleitung notwendiger Bedingungen}
Die Einführung der Lagrange-Multiplikatoren liefert
\begin{align*}
	\bar{J} & = h\left(x(t_b),t_b \right)+\int\limits_{t_a}^{t_b}\left[f_0\left(x(t),u(t),t \right)+\psi(t)^T\left(f(x(t),u(t),t)-\dot{x}(t) \right)
	\right]dt\\
	& \quad + \lambda_a^T\left\{x_a - x(t_a) \right\} + \lambda_b^T z\left(x(t_b) \right)
\end{align*}
mit $\lambda_b\in\mathbb{R}^m$, $\lambda_a\in\mathbb{R}^n$.

Die Motivation ist, dass 
\begin{align*}
	J & = \int F_0(x(t))dt \rightarrow \min
\end{align*}
bei $\underbrace{f\left(x(t), u(t) \right)-\dot{x}(t)=0 }_{h\left(x(t),u(t) \right)\in\mathbb{R}^n }$ dargestellt werden kann in diskreter Form als
\begin{align*}
	J_{diskret} & = \sum\limits_j f_0(x(t_j))\rightarrow \min 
\end{align*}
bei $\left. h\left(x(t_j),u(t_j) \right)\right|_{\forall j}=0$ bzw.
\begin{align*}
	L_{diskret} & = \sum\limits_j f_0(x(t_j)) + \sum\limits_j \underbrace{\psi_j^T}_{=:\psi(t_j)} h\left(x(t_j),u(t_j) \right).
\end{align*}
Dies kann wiederrum dargestellt werden in der Form
\begin{align*}
	\bar{J} & = \int\left(f_0(x(t)) \right) + \psi(t)^T\left(f(x(t),u(t))-\dot{x}(t) \right).
\end{align*}
Es wird die Hamilton-Funktion definiert mit
\begin{align*}
	\Ham\left(x(t),u(t),\psi(t),t \right) & = f_0\left(x(t),u(t),t \right) + \psi(t)^T f\left(x(t),u(t),t \right)
\end{align*}
und erhalten 
\begin{align}
	\begin{split}\label{eqn:kap_2_lagrange_fun}
		\bar{J} & = h\left(x(t_b),t_b \right) + \int\limits_{t_a}^{t_b}\left[H\left(x(t),u(t),\psi(t),t \right)-\psi(t)^T\dot{x}(t) \right]dt\\
				& \quad +\lambda_a^T\left\{x_a-x(t_a) \right\} + \lambda_b^T z\left(x(t_b\right).
	\end{split}
\end{align}
Angenommen wir hätten die optimale Lösung gefunden und wir betrachten die Variationen der Funktionen $u$, $x$, $\psi$ und damit auch $\dot{x}$ auf dem
Intervall $\left(t_a, t_b \right)$, den Vektoren $x(t_a)$, $\lambda_a$, $x(t_b)$, $\lambda_b$ und der Zahl $t_b$, d.h.
$\xi(t)=\xi^{\ast}(t)+\epsilon\tilde{\xi}(t)$ mit $\xi\in\left\{x(t_a),\lambda_a, x(t_b), \lambda_b, t_b\right\}$. Einsetzen in
\eqnref{eqn:kap_2_lagrange_fun} liefert die Lagrange-Funktion
\begin{align*}
	\begin{split}
		\bar{J} & = h\left(x^{\ast}\left(t_b^{\ast}+\epsilon\tilde{t}_b \right) +\epsilon\tilde{x}\left(t_b^{\ast}+\epsilon\tilde{t}_b \right),
		t_b^{\ast}+\epsilon\tilde{t}_b \right)\\
		& \quad + \int\limits_{t_a}^{t_b^{\ast}+\epsilon\tilde{t}_b}\left[\Ham\left(x^{\ast}(t)+\epsilon\tilde{x}(t), u^{\ast}(t)+\epsilon\tilde{u}(t),
		\psi^{\ast}(t)+\epsilon\tilde{\psi}(t),t \right) \right.\\
		& \left. \quad - \left(\psi^{\ast}(t)+\epsilon\tilde{\psi}(t) \right)^T\left(\dot{x}^{\ast}(t)+\epsilon\tilde{\dot{x}}(t) \right)\right]dt\\
		& \quad + \left(\lambda_a^{\ast T}+\epsilon\tilde{\lambda}_a^T \right)\left\{x_a - \left(x^{\ast}(t_a)+\epsilon\tilde{x}(t_a)\right) \right\}\\
		& \quad + \left(\lambda_b^{\ast T}+\epsilon\tilde{\lambda}_b^T \right)z\left(x^{\ast}\left(t_b^{\ast}+\epsilon\tilde{t}_b \right) +
		\epsilon\tilde{x}\left(t_b^{\ast} + \epsilon\tilde{t}_b \right) \right).
	\end{split}
\end{align*}
Man hat
\begin{align*}
	& \frac{\td h}{\td\epsilon}\left(x^{\ast}\left(t_b^{\ast}+\epsilon\tilde{t}_b^{\ast} \right) + \epsilon\tilde{x}\left(t_b^{\ast}+ \epsilon\tilde{t}_b
	\right),t_b^{\ast} + \epsilon\tilde{t}_b \right)\\
	=  & \frac{\d h}{\d x}(\ldots)\left(\dot{x}^{\ast}\left(t_b^{\ast}+\epsilon\tilde{t}_b \right)+\tilde{x}\left(t_b^{\ast}\right)+\epsilon\tilde{t}_b +
	\epsilon\tilde{\dot{x}} \left(t_b^{\ast}+\epsilon\tilde{t}_b \right)\tilde{t}_b \right) + \frac{\d h}{\d t}(\ldots)\tilde{t}_b
\end{align*}
und damit
\begin{align*}
	& \left.\frac{\td h}{\td\epsilon}\left(x^{\ast}\left(t_b^{\ast}+\epsilon\tilde{t}_b \right) + \epsilon\tilde{x}\left(t_b^{\ast}+\epsilon\tilde{t}_b 
	\right),t_b^{\ast}+\epsilon\tilde{t}_b \right)\right|_{\epsilon = 0}\\
	= & \frac{\d h}{\d x}\left(x^{\ast}(t_b^{\ast}),t_b^{\ast} \right)\left(\dot{x}^{\ast}(t_b^{\ast})\tilde{t}_b + \tilde{x}(t_b^{\ast}) \right) +
	\frac{\d h}{\d t}(\ldots)\tilde{t}_b\\
	= & \frac{\d h}{\d x}\left(x^{\ast}(t_b^{\ast}),t_b^{\ast} \right)\dot{x}^{\ast}(t_b^{\ast})\tilde{t}_b + \underbrace{\frac{\d h}{\d
	x}\left(x^{\ast}(t_b^{\ast}),t_b^{\ast} \right)\tilde{x}(t_b^{\ast}) }_{=:\left.\frac{\d h}{\d x}\right|_{t_b} \tilde{x}(t_b)}.
\end{align*}
Einsetzen in \eqnref{eqn:kap_2_lagrange_fun} liefert analog zu Abschnitt \secref{sec:kap_2_grundproblem} die Funktionen $F(\epsilon)$ und
\begin{align*}
	\left.\frac{\td F}{\td \epsilon}\right|_{\epsilon=0} & = \left.\frac{\d h}{\d x}\right|_{t_b}\tilde{x}(t_b) + \left[\frac{\d h}{\d x}\dot{x} +
	\frac{\d h}{\d t}+\Ham - \psi^T\dot{x} \right]_{t_b}\tilde{t}_b\\ 
	& \quad + \int\limits_{t_a}^{t_b}\left[\frac{\d\Ham}{\d
	x}\tilde{x}+\frac{\d\Ham}{\d u}\tilde{u}+\frac{\d\Ham}{\d\psi}\tilde{\psi} - \tilde{\psi}^T\dot{x} - \psi^T\tilde{\dot{x}}\right]dt \\
	& \quad + \tilde{\lambda}_a^T\left\{x_a-x(t_b) \right\} - \lambda_a^T\tilde{x}(t_a)+\tilde{\lambda}_b^T z(x(t_b)) \\
	& \quad + \left.\lambda_b^T\frac{\d z}{\d x}\right|_{t_b}\tilde{x}(t_b)+\lambda_b^T\frac{\d z}{\d x}\dot{x}(t_b)\tilde{t}_b
\end{align*}
mit 
\begin{align*}
	\int\limits_{t_a}^{t_b}\psi^T\tilde{\dot{x}}dt & = \psi^T(t_b)\tilde{x}(t_b)-\psi^T(t_a)\tilde{x}(t_a)-\int\limits_{t_a}^{t_b}\dot{\psi}^T\tilde{x}dt
\end{align*} 
durch partielle Integration ergibt sich
\begin{align*}
\left.\frac{\td F}{\td \epsilon}\right|_{\epsilon=0} & = \textcolor{magenta}{\left[\frac{\d h}{\d t}+\Ham \right]_{t_b}\tilde{t}_b} + \int\limits_{t_a}^{t_b}\left[
\textcolor{teal}{\left(\frac{\d\Ham}{\d x}+\dot{\psi}^T \right)\tilde{x}} + \textcolor{olive}{\frac{\d\Ham}{\d u}\tilde{u}} +
\textcolor{lime}{\left(\frac{\d\Ham}{\d\psi}-\dot{x}^T \right)\tilde{\psi}} \right]dt\\
& \quad + \textcolor{green}{\tilde{\lambda}_a^T\left\{x_a - x(t_a) \right\}} + \left(\psi^T(t_a) - \lambda_a^T \right)\tilde{x}(t_a) +
\textcolor{darkgray}{\tilde{\lambda}_b^Tz(x(t_a))} \\
& \quad + \textcolor{cyan}{ \left[\lambda_b^T\frac{\d z}{\d x}+\frac{\d h}{\d x}-\psi^T \right]_{t_b}\left(\tilde{x}(t_b)+\dot{x}(t_b)\tilde{t}_b \right)}\\
& = 0
\end{align*}

\subsection{Notwendige Bedingungen für Optimallösung}
Die Prozessgleichung wird definiert als
\begin{align}
	\textcolor{lime}{\dot{x}(t) = \nabla_{\psi}\Ham} & = f\left(x(t),u(t),t \right). \label{eqn:kap_2_prozessgleichung}
\end{align}
Die dazugehörige adjungierte Prozessgleichung\footnote{Es kann geschrieben werden \begin{align*}
\frac{\d\Ham}{\d x} & = \frac{\d f_0}{\d x}+\psi^T\underbrace{\frac{\d f}{\d x}}_{\in\mathbb{R}^{n\times n}}\\
\nabla_x\Ham & = \nabla_x f_0+\left[\frac{\d f}{\d x} \right]^T\psi
\end{align*}} ist beschrieben durch
\begin{align}
	\textcolor{teal}{\dot{\psi}(t) = -\nabla_x\Ham } & = -\nabla_x f_0\left(x(t),u(t),t \right)-\left[\frac{\d f}{\d x}(x(t),u(t),t) \right]^T\psi(t) \label{eqn:kap_2_adj_prozessglg}
\end{align}
und die Steuerungsgleichung durch
\begin{align}
	\textcolor{olive}{\nabla_u\Ham\left(x(t),u(t),\psi{t},t \right)} & = 0. \label{eqn:kap_2_steuergleichung}
\end{align}
Dabei bilden Gleichung \eqnref{eqn:kap_2_prozessgleichung} und \eqnref{eqn:kap_2_adj_prozessglg} die kanonischen Differentialgleichungen und \eqnref{eqn:kap_2_prozessgleichung},
\eqnref{eqn:kap_2_adj_prozessglg} und \eqnref{eqn:kap_2_steuergleichung} die sogenannten Hamilton-Gleichungen.\\
\begin{tabular}{lll}
\ac{AB} & \textcolor{green}{$x(t_a)=x_a$}\\
\ac{EB} & Fall A: 	& \textcolor{darkgray}{$z(x(t_b))=0$} und die Transversalitätsbedingung\\
		&			& \textcolor{cyan}{$\left[\frac{\d z}{\d x}(x(t_b)) \right]^T\lambda_b +\nabla_x
h(x(t_b),t_b)-\psi(t_b)=0$} \\
		& Fall B: 	& $x(t_b)=t_b$ mit bekannten $x_a$ und $x_b$\\
		& Fall C: 	& $\nabla_x h(x(t_b),t_b)=\psi(t_b)$\\
		&			& Fall $t_b$ frei ist, so muss zusätzlich $\Ham(x(t_b),u(t_b),\psi(t_b),t_b)=\textcolor{magenta}{-\frac{\d h}{\d t}(x(t_b),t_b)}$\\
		&			& erfüllt sein.
\end{tabular}

\subsection{Grundsätzliche Vorgehensweise zur analytischen Bestimmung der Optimallösung}
\begin{enumerate}[label=(S\arabic*)]
  \item Umstellen der Steuerungsgleichung nach $u$ liefert 
  \begin{align}
  	u(t) & = \mathcal{U}\left(x(t),\psi(t),t \right). \label{eqn:kap_2_vor_optlsg_s1_u}
  \end{align}
  Einsetzen in kanonsiche Differentialgleichung (Elimination von $u$ ergibt)
  \begin{align}
  	\dot{x} & = w(x,\psi,t). \label{eqn:kap_2_vor_optlsg_s1_x}
  \end{align}
  \item Bestimmen der allgemienen Lösung von \eqnref{eqn:kap_2_vor_optlsg_s1_x} mit dem Integrationsparameter $c\in\mathbb{R}^{2n}$
  \begin{align}
  	x & = x(t,c), & \psi=\psi(t,c)	\label{eqn:kap_2_vor_optlsg_s2}
  \end{align}
  \item Anpassung der Lösung an die Randbedingungen\\
  \begin{tabular}{ll}
  Fall A	& $x(t_a,c)=x_a$, $z\left(x(t_b,c) \right)=0$,\\ 
  			& $\left[\frac{\d z}{\d x}\left(x(t_b,c) \right) \right]^T\underbrace{\lambda_b}_{\in\mathbb{R}^m}+\nabla_x h\left(x(t_b,c),t_b
  			\right)-\psi(t_b,c)=0$\\
  Fall B	& $x(t_a,c)=x_a$, $x(t_b,c)=x_b$\\
  Fall C	& $x(t_a,c)=x_a$, $\nabla_x h\left(x(t_b,c),t_b \right) = \psi(t_b,c)$\\
  			& Falls $t_b$ frei ist: $\Ham\left(x(t_b,c),\mathcal{U}(x(t_b,c)),\psi(t_b,c),t_b \right)=\frac{\d h}{\d t}\left(x(t_b,c),t_b \right)$
  \end{tabular}\\
  Dabei $x_a$ als Variable mitführen, also ist $c=c(x_a)$. Falls $t_b$ frei ist, so gilt $t_b=t_b(x_a)$.
  \item Einsetzen von $c(x_a)$ in \eqnref{eqn:kap_2_vor_optlsg_s2} ergibt die optimale (Zustands- und Kozustands-)Trajektorie 
  \begin{align}
  	x\left(t,c(x_a) \right) & =: x^{\ast}(t,x_a)	\label{eqn:kap_2_vor_optlsg_s4}
  \end{align}
  und 
  \begin{align*}
  	\psi\left(t,c(x_a) \right) & =: \psi^{\ast}(t,x_a).
  \end{align*}
  Eingesetzt in \eqnref{eqn:kap_2_vor_optlsg_s1_u} erhält man die optimale Steuertrajektorie
  \begin{align}
  	\mathcal{U}\left(x^{\ast}(t,x_a), \psi^{\ast}(t,x_a),t \right) & =: u^{\ast}(t,x_a).	\label{eqn:kap_2_vor_optlsg_s5}
  \end{align}
  \item Umstellen von \eqnref{eqn:kap_2_vor_optlsg_s4} nach $x_a$ und einsetzen in \eqnref{eqn:kap_2_vor_optlsg_s5} liefert das Regelgesetz
  \begin{align*}
  	u^{\ast}(t) & = K\left(x(t),t \right).
  \end{align*}
\end{enumerate}
Die Schritte (S1) bis (S4) liefern die in \figref{fig:kap_2_vor_optlsg_s1s4} dargestellten Trajektrtorien und Schritt (S5) die in
\figref{fig:kap_2_vor_optlsg_s5} dargestellte Trajektorie.
\begin{figure}[htb]
	\centering
	\input{tikz/dummy}
	\caption{Trajektorien der Schritte (S1) bis (S4)}
	\label{fig:kap_2_vor_optlsg_s1s4}
\end{figure}
\begin{figure}[htb]
	\centering
	\input{tikz/dummy}
	\caption{Trajektorie des Schrittes (S5)}
	\label{fig:kap_2_vor_optlsg_s5}
\end{figure}
\begin{exmp}\label{exmp:kap_2_vor_optlsg_1}
Sei $\dot{x}=ax+bu$ mit $a,b\in\mathbb{R}^1$, $t_a=0$, $x(0)=x_a$ gegeben. Weiterhin ist $t_b$ gegeben und damit nicht frei. $x(t_b)=0$, d.h. es
wird Fall B betrachtet mit dem "`energieoptimalen"' Kostenfunktional 
\begin{align*}
	J & = \frac12\int\limits_0^{t_b}u(t)^2dt.
\end{align*}
Wir haben
\begin{align*}
	\Ham & = \frac12 u^2 + \psi(ax+bu),\\
	\dot{x} & = \nabla_{\psi}\Ham = ax+bu,\\
	\dot{\psi} & = -\nabla_x\Ham = -a\dot \psi,\\
	\nabla_u\Ham & = u+b\psi = 0.
\end{align*}
Damit ist 
\begin{align}
	u & = -b\psi.	\label{eqn:kap_2_vor_optlsg_u}
\end{align}
Im nächsten Schritt werden die kanonischen Differentialgleichungen gelöst. Die Lösung von 
\begin{align*}
	\dot{x} & = ax - b^2\psi\\
	\dot{\psi} & = -a\cdot\psi
\end{align*}
liefert
\begin{align}
	x(t) & = x(0)e^{at}+\frac{b^2\psi(0)}{2a}\left(e^{-at}-e^{at} \right)	\label{eqn:kap_2_vor_optlsg_x}\\
	\psi(t) & = \psi(0)e^{-at}.		\label{eqn:kap_2_vor_optlsg_psi}
\end{align}
In \eqnref{eqn:kap_2_vor_optlsg_x} wird $t=t_b$ zur Betrachtung des Endzeitpunktes $t_b$ gesetzt und $x(t_b)= 0$. Umstellen nach $\psi(0)$ liefert
\begin{align}
	\psi(0) & = -\frac{2a}{b^2}\frac{e^{at_b}}{e^{-at_b}-e^{at_b}}x(0).	\label{eqn:kap_2_vor_optlsg_psi0}
\end{align}
Eingesetzt in \eqnref{eqn:kap_2_vor_optlsg_x} erhält man
\begin{align}
	x^{\ast}(t,x(0)) & = x(0)\frac{e^{-a(t_b-t)}-e^{a(t_b-t)}}{e^{-at_b}-e^{at_b}}	\label{eqn:kap_2_vor_optlsg_xast}
\end{align}
und \eqnref{eqn:kap_2_vor_optlsg_u} wird mit \eqnref{eqn:kap_2_vor_optlsg_psi} und \eqnref{eqn:kap_2_vor_optlsg_psi0} zu
\begin{align}
\begin{split}\label{eqn:kap_2_vor_optlsg_uast}
	u^{\ast}(t,x(0)) & = -b\psi(0)e^{at}\\
	& = \frac{2a}{b}\frac{e^{a(t_b-t)}}{e^{-at_b}-e^{at_b}} x(0).
\end{split}
\end{align}
\eqnref{eqn:kap_2_vor_optlsg_xast} umgestellt nach $x(0)$ und eingesetzt in \eqnref{eqn:kap_2_vor_optlsg_uast} liefert das Regelgesetz
\begin{align}
	u^{\ast}(t) & = k(t) x(t)
\end{align}
mit
\begin{align*}
	k(t) & = \frac{2a}{b}\frac{e^{a(t_b-t)}}{e^{-a(t_b-t)}-e^{a(t_b-t)}}.
\end{align*}
Der optimale Regler ist linear, zeitvariant und es gilt
\begin{align*}
	\lim\limits_{t\rightarrow t_b}\left|k(t)\right| & = \infty.
\end{align*}
Eine Verstäkrung gegen $\infty$ ist sinnig. Sie entsteht durch die harten Endbedingungen. Es wären weiche Endbedingungen sinnvoll, siehe
\exmpref{exmp:kap_2_vor_optlsg_2}. Die Trajektorien von $u$, $x$ und $\psi$ sind in \figref{fig:kap_2_vor_optlsg_exmp_1} dargestellt. Der Verlauf der
Reglerverstärkung ist in \figref{fig:kap_2_vor_optlsg_exmp_2_k} abgebildet. 
\end{exmp}
\begin{figure}[htb]
	\centering
	\input{tikz/dummy}
	\caption{Trajektories von \exmpref{exmp:kap_2_vor_optlsg_1} mit festem Endzustand}
	\label{fig:kap_2_vor_optlsg_exmp_1}
\end{figure}
\begin{exmp}\label{exmp:kap_2_vor_optlsg_2}
Sei $\dot{x}=ax+bu$ mit $a,b\in\mathbb{R}^1$, $t_a=0$, $x(0)=x_a$ gegeben. $t_b$ wird als frei angenommen und das Kostenfunktional als
\begin{align*}
	J & = \frac12 Sy(t_b)^2 + \frac12\int\limits_0^{t_b}u(t)^2dt.
\end{align*}
Das heisst, es wird Fall C betrachtet. So ist anstelle von $x(t_b)=0$ die Randbedinung $Sx(t_b)=\psi(t_b)$ zu erfüllen. Darin müssen Gleichung
\eqnref{eqn:kap_2_vor_optlsg_x} und \eqnref{eqn:kap_2_vor_optlsg_psi} an der Stelle $t=t_b$ eingesetzt und nach $\psi(0)$ umgestellt werden. Damit
erhält man $x^{\ast}\left(t,x(0) \right)$, $\psi^{\ast}\left(t,x(0) \right)$ und $u^{\ast}\left(t,x(0) \right)$, sowie das Regelgesetz
\begin{align*}
	u^{\ast}(t) & = k(t) x(t)
\end{align*}
mit
\begin{align*}
	k(t) & = \frac{-2a S}{b\left(S-\left(S-\frac{2a}{b^2} \right)e^{-2a(t_b-t)} \right)}
\end{align*}
für den gilt, dass $k(t_b)=-bS$ gilt.

Für $t_b\rightarrow\infty$ gilt für jedes $t$ in beiden Fällen
\begin{align*}
	k(t) & = \left\{\begin{array}{cl}
	0 & \text{für} a < 0\\
	unbestimmt & \text{für} a = 0\\
	-\frac{2a}{b} & \text{für} a > 0
	\end{array}\right. .
\end{align*}
Der Prozess ist bei $a<0$ stabil und damit ist kein Stellaufwand notwendig. Wenn der Prozess instabil ist, $a > 0$, konvergiert der Zustand gegen
$\infty$. Wenn der Prozess integrales Verhalten aufweist, $a=0$, ist kein Minimum vorhanden.
\end{exmp}
\begin{figure}[htb]
	\centering
	\input{tikz/dummy}
	\caption{Trajektories von \exmpref{exmp:kap_2_vor_optlsg_2} mit Gewichtung des Endzustandes}
	\label{fig:kap_2_vor_optlsg_exmp_2}
\end{figure}
\begin{figure}[htb]
	\centering
	\input{tikz/dummy}
	\caption{Reglerverstärkungen von \exmpref{exmp:kap_2_vor_optlsg_1} und \exmpref{exmp:kap_2_vor_optlsg_2}}
	\label{fig:kap_2_vor_optlsg_exmp_2_k}
\end{figure}
Es sind zwei Übungen unter \picref{sec:uebung_anal_best_opt_lsg}{Vorgehensweise zur analytischen Bestimmung der Optimallösung} im Anhang zu finden.

\subsection{Numerische Lösung am Beispiel "`Fall C und fester Endzeit $t_b$"'}
Zur Lösung der "`Endwertaufgabe"' $\dot{\psi}=\nabla_x \Ham$ mit gegeben Endwert $\psi(t_b)$ und unter der Annahme, dass $x(t)$ und $u(t)$ gegeben
sind. Wir setzen $t=t(\tau)=t_b+t_a-\tau$, vgl. \figref{fig:kap_2_fallc_tbfest_ttau} und mit 
\begin{align*}
	\Psi(\tau) & := \psi(t(\tau)) = \psi(t_b+t_a-\tau)
\end{align*}
erhält man 
\begin{align*}
	\dot{\Psi}(\tau) & = \frac{d\psi(t(\tau))}{d\tau} = \left.\frac{d\psi(t)}{dt}\right|_{t=t(\tau)}\frac{dt}{d\tau}\\
	& = \left.-\frac{d\psi(t)}{dt}\right|_{t=t(\tau)}=\left.-\dot{\psi}(t)\right|_{t=t(\tau)}\\
	& = \left.\nabla_x \Ham(x(t),u(t),\psi(t),t)\right|_{t=\tau}
\end{align*}
\begin{figure}[htb]
	\centering
	\input{tikz/dummy}
	\caption{Darstellung der linearen Funktion $t=t(\tau)$}
	\label{fig:kap_2_fallc_tbfest_ttau}
\end{figure}
\begin{figure}[htb]
	\centering
	\input{tikz/dummy}
	\caption{Entwicklung von $\psi$ in Abhängigkeit von $t$ und $\tau$}
	\label{fig:kap_2_fallc_tbfest_psi}
\end{figure}
Damit ist die Anfangswertaufgabe 
\begin{align*}
	\dot{\Psi}(\tau) & = \nabla_x \Ham(x(t_b+t_a-\tau),u(t_b+t_a-\tau),\psi(\tau),t_b+t_a-\tau)
\end{align*}
mit dem \ac{AW} $\Psi(t_a)=\psi(t_b)$ zu lösen für $\tau\in[t_a,t_b]$ und es gilt
\begin{align*}
	\psi(t) & = \psi(t_b+t_a-\tau).
\end{align*}

Zur Lösung des nichtlinearen Gleichungssystems $\nabla_u \Ham =0$ kann das \textsc{Newton}-Verfahren verwendet werden. Bekannt ist, dass für eine
differenzierbare Funktion $f:\mathbb{R}^1\rightarrow\mathbb{R}^1$ gilt
\begin{align*}
	f(x) & = f(\bar{x})+f'(\bar{x})(x-\bar{x})+\mathcal{O}(x-\bar{x}),
\end{align*}
wobei $\mathcal{O}(h)$ für eine beliebeige Funktion $g:\mathbb{R}^1\rightarrow\mathbb{R}^1$ mit $\lim\limits_{h\rightarrow 0}\frac{g(h)}{h}=0$
steht.\\
\begin{figure}[htb]
	\centering
	\input{tikz/dummy}
	\caption{Darstellung \textsc{Newton}-Verfahren}
	\label{fig:kap_2_fallc_newton}
\end{figure}
$x=\bar{x}-\frac{f(x)}{f'(x)}$ liefert die iterative Vorschrift
\begin{align*}
	x^{k+1} & = x^k - \alpha\frac{f\left(x^k\right)}{f'\left(x^k \right)}
\end{align*}
mit $\alpha\in(0,1]$. Falls $\alpha\in(0,1)$ gilt, spricht man von einem gedämpften \textsc{Newton}-Verfahren. Allgemein für differenzierbare
Funktionen $F:\mathbb{R}^n\rightarrow\mathbb{R}^n$ kann geschrieben werden:\\
Löse $F(x)=0$ mittels
\begin{align*}
	x^{k+1} & = x^k - \alpha F'\left(x^k\right)^{-1}F(k)
\end{align*}
mit der Jacobimatrix $F'\left(x^k\right)$ an der Stelle $x^k$.

Bei der Anwendung des Verfahrens auf 
\begin{align*}
 \nabla_x\Ham\left(x(t),u(t),\psi(t),t \right) & = 0
\end{align*}
ergibt sich die Iterationsvorschrift zu
\begin{align*}
	u^{k+1}(t) & ) u^{k}(t) -\alpha\nabla_{uu}\Ham\left(x(t),u^k(t),\psi(t),t \right)^{-1}\nabla_u\Ham\left(x(t),u^k(t),\psi(t),t \right)
\end{align*}
Für ein gegebenes $x(t)$ und $\psi(t)$ ist die Vorschrift für alle $t$ abzuarbeiten.\\
Ein Algorithmus zur Bestimmung von $u$ kann wie folgt dargestellt werden.
\begin{enumerate}[label=(S\arabic*)]
  \item Setze einen Startwert $u(t)$, $t\in[t_a,t_b]$.
  \item Löse \ac{AWA} $\dot{x}=f\left(x(t),u(t),t \right)$ mit $x(t_a)=x_a$ und liefert $x(t)$, $t\in[t_a,t_b]$.
  \item Löse \ac{AWA}
  \begin{align*}
  	\dot{\Psi}(\tau) & = \nabla_x\Ham\left(x(t_b+t_a-\tau),u(t_b+t_a-\tau),\psi(\tau),t_b+t_a-\tau \right)\\
  	\Psi(t_a) & = \nabla_xh\left(x(t_b),t_b \right)
  \end{align*}
  mit $\tau\in[t_a,t_b]$ und liefert $\psi(t)=\Psi\left(t_b + t_a -\tau\right)$, $t\in[t_a,t_b]$.
  \item Aktualisiere 
  \begin{align*}
  	u(t) & \leftarrow u(t)-\underbrace{\alpha\nabla_{uu}\Ham\left(x(t),u(t),\psi(t),t \right)^{-1}\nabla_u\Ham\left(x(t),u(t),\psi(t),t \right)
  	}_{\Delta u}
  \end{align*} 
  mit $t\in[t_a,t_b]$.
  \item Falls Abbruchbedingung, bspw. $\|\Delta u\|$ klein oder $\|\Delta J\|$ klein, erfüllt ist, dann Stopp, andernfalls gehe zu (S2).
\end{enumerate}
\begin{exmp}
Es wird der vorgestellten Algorithmus in Form von Pseudocode auf das Beispiel \exmpref{exmp:kap_2_vor_optlsg_2} angewendet. Der Prozess ist
beschrieben durch
\begin{align*}
	\dot{x} & = ax + bu
\end{align*}
mit gegebenen $x(t_a)=x_a$ und $t_b$ und dem Kostenfunktional
\begin{align*}
	J & = \frac12 Sx(t_b)^2 + \frac12\int\limits_{t_a}^{t_b}u(t)^2dt. 
\end{align*}
\begin{enumerate}[label=(S\arabic*)]
  \item Setze Startwert für die zeitdiskretisierte Steuerfunktion $\begin{bmatrix}
  u(t_a)\\ \vdots\\ t(t_b)
  \end{bmatrix}$ in diskreten Zeitpunkten $\begin{bmatrix}
  t_a\\ \vdots\\ t_b
  \end{bmatrix}$ mit geeigneter Diskretisierung.
  \item Prozesssimulation\footnote{\textsc{Matlab}: $\text{\lstinline[columns=fixed]{lsim}}(\dot{x}=ax+bu,\begin{bmatrix}
  u(t_a)\\ \vdots\\u(t_b)
  \end{bmatrix},\begin{bmatrix}
  t_a\\ \vdots\\ t_b
  \end{bmatrix},x_a)$} mit gegebenen \ac{AW} $\begin{bmatrix}
  x(t_a)\\ \vdots\\x(t_b)
  \end{bmatrix}$ und Steuerfunktion.
  \item "`Rückwärtssimulation"'\footnote{\textsc{Matlab}: $\text{\lstinline[columns=fixed]{exp}}(a(\begin{bmatrix}
  t_a\\ \vdots\\ t_b
  \end{bmatrix} - t_a))Sx(t_b)$} der adjungierten Prozessgleichung
  $\begin{bmatrix} \psi(t_a)\\ \vdots\\ \psi(t_b)
  \end{bmatrix}$ aus 
  \begin{align*}
  	\Ham & = \frac12 u^2 + \psi\left(ax+bu\right)\\
  	\nabla_x\Ham & = a\psi\\
  	\dot{\Psi}(\tau) & = a\Psi(\tau)\\
  	\Psi(t_a) & = Sx(t_b), & \tau\in[t_a,t_b]\\
  	\Psi(\tau) & = e^{a(\tau -t_a)}Sx(t_b).
  \end{align*}
  $t$ läuft von $t_b$ nach $t_a$ und $\tau$ läuft von $t_a$ nach $t_b$.
  \item Aktualisierung der Steuerfunktion
  \begin{align*}
  	\begin{bmatrix}
  u(t_a)\\ \vdots\\ u(t_b)
  \end{bmatrix} & \leftarrow \begin{bmatrix}
  u(t_a)\\ \vdots\\ u(t_b)
  \end{bmatrix} - \alpha\left(\begin{bmatrix}
  u(t_a)\\ \vdots\\ u(t_b)
  \end{bmatrix} + \begin{bmatrix}
  \psi(t_a)\\ \vdots\\ \psi(t_b)
  \end{bmatrix}b \right)
  \end{align*}
  aus $\nabla_u\Ham = u+\psi b$, $\nabla_{uu}=1$ und
  \begin{align*}
  	u(t) & \leftarrow u(t) - \alpha\left(u(t) + \psi(t)b \right).
  \end{align*}
  \item Falls Abbruchbedingung erfüllt ist, dann Stopp, andernfalls gehe zu (S2).
\end{enumerate}
\end{exmp}
Es ist eine Übung unter \picref{sec:uebung_num_best_opt_lsg}{Vorgehensweise zur numerischen Bestimmung der Optimallösung} im Anhang zu finden.

\subsection{Anwendung zur Umformung von Optimierungsproblemen am Beispiel des \NoCaseChange{\acl{LQR}}-Problems}
Minimiere das Gütefunktional
\begin{align*}
	J  & = \frac12 x^T(t_b)Gx(t_b)+\frac12\int\limits_{t_a}^{t_b}\left[x^T(t)Q(t)x(t)+u^TR(t)u(t)\right]dt
\end{align*}
bei dem Prozess 
\begin{align*}
	\dot{x}(t) & = A(t)x(t)+B(t)u(t)
\end{align*}
mit den gegebenen Werten $x(t_a)=x_a$, $t_a$, $x_a$ und $t_b$, wobei der Zustandswert zur Endzeit $x(t_b)$ frei ist. Weiterhin sollen $G\ge 0$,
$Q(t)\ge 0$ (semipositiv defintit), $R(t)>0$ (positiv definit)\footnote{WEnn $R(t)$ smidefinit wäre, würde es $u$ geben, die keine Kosten erzeugen.}
und $Q(t)$, sowie $R(t)$ stetig differenzierbar sein. Der Ausgang wird berechnet mit
\begin{align*}
	y & = C x
\end{align*}
mit der Wichtung von $y$
\begin{align*}
	y^T W y & = x^T\underbrace{c^TWc}_{Q(t)}x.
\end{align*}
Es wird die Hamilton-Funktion gebildet
\begin{align*}
	\Ham & = \frac12\left(x^T(t) Q(t)x(t)+u^T(t)R(t)u(t)+\psi^T(t)\left(A(t)x(t)+B(t)u(t) \right) \right).
\end{align*}
Damit kann die kanonische Differentialgleichung und die \ac{RB}en angeben werden
\begin{align*}
	\dot{x}(t) & = \nabla_{\psi}\Ham = A(t)x(t)+B(t)u(t),\\
	\dot{\psi}(t) & = -\nabla_x\Ham = -\left(Q(t)x(t) + A^T(t)\psi(t) \right),\\
	x(t_a) & = x_a, \\
	\psi(t_b) & = \nabla_x h=G x(t_b).
\end{align*}
Die Steuerungsgleichung 
\begin{align*}
	\nabla_u\Ham & = R(t) u(t) + B^T(t)\psi(t)=0
\end{align*}
liefert
\begin{align*}
	u(t) & = -R^{-1}(t)B^T(t)\psi(t).
\end{align*}
Wir haben ein lineares homogenes Differentialgleichungssystem und $\psi(t_b)$ ist linear von $x(t_b)$ abhängig. Dies motiviert zu dem Ansatz
\begin{align*}
	\psi(t) & = X(t)x(t), & \forall t\in[t_a,t_b].
\end{align*}
Dann gilt für jedes $x(t)$
\begin{align*}
	\dot{\psi}(t) & = \dot{X}x + X\dot{x}\\
	& = \dot{X}x + X\left(Ax-BR^{-1}B^TXx \right)\\
	& = -Qx-A^TXx
\end{align*}
was auf
\begin{align*}
	\left(\dot{X} + X\left(A-BR^{-1}B^TX \right) + Q +A^TX \right)x & = 0.
\end{align*}
führt, was wiederrum die Matrix-Ricatti-Differentialgleichung
\begin{align*}
	\dot{X} & = -A^TX -XA + XBR^{-1}B^TX -Q
\end{align*}
mit der Endbedingung $x(t_b)$ liefert. Das Regelgesetz kann zu
\begin{align*}
	u(t) & = \underbrace{-R^{-1}(t)B(t)X(t)}_{=:k(t)}x(t)
\end{align*}
formuliert werden, was eine lineare zeitvariante Zustandsrückführung darstellt.

\section{Maximumprinzip von Pontojaju}
Die Aufgabe ist das Kostenfunktional
\begin{align*}
	J & = h\left(x(t_b),t_b \right) + \int\limits_{t_a}^{t_b} f_0(x(t),u(t),t)dt\rightarrow\min
\end{align*}
für den Prozess
\begin{align*}
	\dot{x}(t) & = f\left( x(t),u(t),t \right),
\end{align*}
mit $u:[t_a,t_b]\rightarrow \Omega\subset\mathbb{R}^p$ mit dem zulässigen Bereich $\Omega$, der zeitvariant, abgeschlossen und konvex ist.\\
Die \ac{AB} seien gegeben mit gegebenen $t_a$, $x_a$ mit $x(t_a)=x_a$.\\
Die \ac{EB} seien gegeben mit gegebenen oder freien $t_b$ und $z(x(t_b))=0$ mit $z:\mathbb{R}^n\rightarrow\mathbb{R}^m$, d.h. es wird Fall A
betrachtet.\\
$h$, $f_0$, $f$ und $z$ seinen stetig differenzierbar bezüglich aller Argumente. Es ist keine Beschreibung für $x(t)$ für $t\in[t_a,t_b]$ gegeben.

\begin{defi}
Die Lösung des Steuerungsproblems heisst singulär, falls
\begin{enumerate}[label=(\Roman*)]
  \item $\lambda_0=0$ oder
  \item $H\neq H(u)$ für $t\in[t_1,t_2]\subseteq[t_a,t_b]$ mit $t_1<t_2$, d.h. es gibt ein Intervall mit Lösungen größer Null auf dem $H$ keine
  explizite Funktion der Steuergröße ist.
\end{enumerate}
\end{defi}

\begin{remark}[Zum Fall (I)]

\end{remark}

\begin{exmp}
Minimiere $J = \int\limits_0^1 u(t)dt$ für den Prozess $\dot{x}=u(t)^2$ unter der \ac{NB} $x(0)=x(1)=0$. Offenbar erfüllt nur $u\equiv 0$ die \ac{NB}
und ist daher optimal. Mit der Hamilton-Funktion
\begin{align*}
	\Ham\left(x,u,\psi,\lambda_0,t \right) & = \lambda_0u + \psi u^2
\end{align*}
gilt
\begin{align*}
	0 & = \Ham_u = \lambda_0 2\psi u
\end{align*}
und
\begin{align*}
	\dot{\psi}& = -\Ham_x=0.
\end{align*} 
Damit ist $\psi=const$ und damit ein unbeschränktes Problem. Falls $\psi = 0$, so gilt auch $\lambda_0=0$. Angenommen $\psi\neq 0$, so ist
$u=-\frac{\lambda_0}{2\psi}$. Falls $\lambda_0\neq 0$ ist, so wäre $x(1)>0$, d.h. diese $u$ wäre nicht zulässig. Also muss $\lambda_0=0$ gelten.
\end{exmp}


\begin{remark}[Zum Fall (II)]

\end{remark}

\begin{exmp}[Zeitoptimale Steuerung eines Doppelintegrators]

\end{exmp}
\begin{exmp}[Verbrauchsoptimale Steuerung eines Doppelintegrators]

\end{exmp}
\begin{exmp}[Anwendung des Satz von Feldbaum]

\end{exmp}
